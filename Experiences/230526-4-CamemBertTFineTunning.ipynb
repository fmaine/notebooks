{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ec4689",
   "metadata": {},
   "source": [
    "# Plateforme Agnostique de Traitement et d'Analyse des Textes\n",
    "### Carnet d'expérimentation\n",
    "---\n",
    "\n",
    "## Sujet : Fine tunning de CamemBERT pour classification infox\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601e626",
   "metadata": {},
   "source": [
    "# Initialisations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525fef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rs = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0de4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Geek/Work/Patat\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32256b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm,trange\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b13f54",
   "metadata": {},
   "source": [
    "# Préparation Données\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18533365",
   "metadata": {},
   "source": [
    "## Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b435d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.file\n",
    "\n",
    "filename = 'data/prod/230517-OIDS-Label.pickle'\n",
    "\n",
    "df_label = patat.util.file.pickle_load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394eb154",
   "metadata": {},
   "source": [
    "## Labels ou textes Nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f6f1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73feab00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label['infox'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e535748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label[df_label['infox'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d454d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e71e98",
   "metadata": {},
   "source": [
    "## Données dupliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6b9499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.duplicated(subset='text').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8c481ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.duplicated(subset='url').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e56e6c",
   "metadata": {},
   "source": [
    "## Equilibrage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c59b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='infox', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_count = df_label['infox'].value_counts()\n",
    "sns.barplot(x=label_count.index, y=label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "babd8a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>infox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Guerre en Ukraine: Emmanuel Macron prévient le...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>La vaccination Covid : un marquage de « type b...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Colonialisme énergétique\\nVisite d’État du pré...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>De l’importance d’une Assemblée vraiment natio...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Quelle politique migratoire pour la France ? –...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Des scientifiques de Harvard et de Johns Hopki...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>L’armée russe achète des exemplaires d’armemen...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>ONU – Le Premier ministre de Nouvelle-Zélande ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>Pandémie ou le retour du grand Pan\\nAu cours d...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Le président Trump dénonce la corruption de la...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  infox\n",
       "609  Guerre en Ukraine: Emmanuel Macron prévient le...    0.0\n",
       "705  La vaccination Covid : un marquage de « type b...    0.0\n",
       "26   Colonialisme énergétique\\nVisite d’État du pré...    0.0\n",
       "565  De l’importance d’une Assemblée vraiment natio...    0.0\n",
       "231  Quelle politique migratoire pour la France ? –...    0.0\n",
       "..                                                 ...    ...\n",
       "112  Des scientifiques de Harvard et de Johns Hopki...    1.0\n",
       "157  L’armée russe achète des exemplaires d’armemen...    1.0\n",
       "522  ONU – Le Premier ministre de Nouvelle-Zélande ...    1.0\n",
       "847  Pandémie ou le retour du grand Pan\\nAu cours d...    1.0\n",
       "151  Le président Trump dénonce la corruption de la...    1.0\n",
       "\n",
       "[746 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df_label[df_label['infox'] == 0]\n",
    "df_1 = df_label[df_label['infox'] == 1]\n",
    "\n",
    "min_sample = min(len(df_0),len(df_1))\n",
    "\n",
    "\n",
    "df_0=df_0.sample(min_sample,random_state=_rs)\n",
    "df_1=df_1.sample(min_sample,random_state=_rs)\n",
    "df_ml = pd.concat([df_0,df_1])[['text','infox']]\n",
    "\n",
    "df_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04014933",
   "metadata": {},
   "source": [
    "# Experience\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7a36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c136c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining constants\n",
    "epochs = 2\n",
    "MAX_LEN = 512\n",
    "batch_size = 16\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a2921e",
   "metadata": {},
   "source": [
    "## Spliting Training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c0097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CamemBERT tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)\n",
    "\n",
    "# Creates list of texts and labels\n",
    "text = df_ml['text'].to_list()\n",
    "labels = df_ml['infox'].astype(int).to_list()\n",
    "\n",
    "#user tokenizer to convert sentences into tokenizer\n",
    "input_ids = [\n",
    "    tokenizer.encode(sent, add_special_tokens=True, max_length=MAX_LEN,truncation=True)\n",
    "    for sent in text\n",
    "]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids,\n",
    "                          maxlen=MAX_LEN,\n",
    "                          dtype=\"long\",\n",
    "                          truncating=\"post\",\n",
    "                          padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i > 0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43fbe259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(\n",
    "    input_ids, labels, attention_masks, random_state=42, test_size=0.2)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb3a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks,\n",
    "                                validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data,\n",
    "                                   sampler=validation_sampler,\n",
    "                                   batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb2be072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# CamemBERT model\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Defining the parameters and metrics to optimize\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [{\n",
    "    'params':\n",
    "    [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate':\n",
    "    0.01\n",
    "}, {\n",
    "    'params':\n",
    "    [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate':\n",
    "    0.0\n",
    "}]\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c40cc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acc30ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Step: 0\n",
      "Epoch : 0 Step: 1\n",
      "Epoch : 0 Step: 2\n",
      "Epoch : 0 Step: 3\n",
      "Epoch : 0 Step: 4\n",
      "Epoch : 0 Step: 5\n",
      "Epoch : 0 Step: 6\n",
      "Epoch : 0 Step: 7\n",
      "Epoch : 0 Step: 8\n",
      "Epoch : 0 Step: 9\n",
      "Epoch : 0 Step: 10\n",
      "Epoch : 0 Step: 11\n",
      "Epoch : 0 Step: 12\n",
      "Epoch : 0 Step: 13\n",
      "Epoch : 0 Step: 14\n",
      "Epoch : 0 Step: 15\n",
      "Epoch : 0 Step: 16\n",
      "Epoch : 0 Step: 17\n",
      "Epoch : 0 Step: 18\n",
      "Epoch : 0 Step: 19\n",
      "Epoch : 0 Step: 20\n",
      "Epoch : 0 Step: 21\n",
      "Epoch : 0 Step: 22\n",
      "Epoch : 0 Step: 23\n",
      "Epoch : 0 Step: 24\n",
      "Epoch : 0 Step: 25\n",
      "Epoch : 0 Step: 26\n",
      "Epoch : 0 Step: 27\n",
      "Epoch : 0 Step: 28\n",
      "Epoch : 0 Step: 29\n",
      "Epoch : 0 Step: 30\n",
      "Epoch : 0 Step: 31\n",
      "Epoch : 0 Step: 32\n",
      "Epoch : 0 Step: 33\n",
      "Epoch : 0 Step: 34\n",
      "Epoch : 0 Step: 35\n",
      "Epoch : 0 Step: 36\n",
      "Epoch : 0 Step: 37\n",
      "Train loss: 0.6659990172637137\n",
      "Validation Accuracy: 0.75625\n",
      "Epoch : 1 Step: 0\n",
      "Epoch : 1 Step: 1\n",
      "Epoch : 1 Step: 2\n",
      "Epoch : 1 Step: 3\n",
      "Epoch : 1 Step: 4\n",
      "Epoch : 1 Step: 5\n",
      "Epoch : 1 Step: 6\n",
      "Epoch : 1 Step: 7\n",
      "Epoch : 1 Step: 8\n",
      "Epoch : 1 Step: 9\n",
      "Epoch : 1 Step: 10\n",
      "Epoch : 1 Step: 11\n",
      "Epoch : 1 Step: 12\n",
      "Epoch : 1 Step: 13\n",
      "Epoch : 1 Step: 14\n",
      "Epoch : 1 Step: 15\n",
      "Epoch : 1 Step: 16\n",
      "Epoch : 1 Step: 17\n",
      "Epoch : 1 Step: 18\n",
      "Epoch : 1 Step: 19\n",
      "Epoch : 1 Step: 20\n",
      "Epoch : 1 Step: 21\n",
      "Epoch : 1 Step: 22\n",
      "Epoch : 1 Step: 23\n",
      "Epoch : 1 Step: 24\n",
      "Epoch : 1 Step: 25\n",
      "Epoch : 1 Step: 26\n",
      "Epoch : 1 Step: 27\n",
      "Epoch : 1 Step: 28\n",
      "Epoch : 1 Step: 29\n",
      "Epoch : 1 Step: 30\n",
      "Epoch : 1 Step: 31\n",
      "Epoch : 1 Step: 32\n",
      "Epoch : 1 Step: 33\n",
      "Epoch : 1 Step: 34\n",
      "Epoch : 1 Step: 35\n",
      "Epoch : 1 Step: 36\n",
      "Epoch : 1 Step: 37\n",
      "Train loss: 0.524982562190608\n",
      "Validation Accuracy: 0.7729166666666667\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating our model\n",
    "# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n",
    "train_loss_set = []\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for e in range(epochs):\n",
    "    # Tracking variables for training\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        print(f'Epoch : {e} Step: {step}')\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Get loss value\n",
    "        loss = outputs[0]\n",
    "        # Add it to train loss list\n",
    "        train_loss_set.append(loss.item())\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "    # Tracking variables for validation\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = outputs[:2]\n",
    "\n",
    "        # Move logits and labels to CPU if GPU is used\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f033a56a",
   "metadata": {},
   "source": [
    "## Reecriture en cours pour reprendre les métriques standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8efc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Loss and optimizer\n",
    "\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "### 3. Training loop - MPS\n",
    "\n",
    "X_train=X_train.to(device)\n",
    "X_test=X_test.to(device)\n",
    "y_train=y_train.to(device)\n",
    "y_test=y_test.to(device)\n",
    "\n",
    "%%time\n",
    "scores=[]\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Forward pass and loss\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_func(y_pred, y_train)\n",
    "\n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            y_predicted = model(X_test)\n",
    "            y_predicted_cls = y_predicted.round()\n",
    "            pred = y_predicted.to('cpu').T.numpy().round()[0]\n",
    "            proba = y_predicted.to('cpu').T.numpy()[0]\n",
    "            true = y_test.to('cpu').T.numpy()[0]\n",
    "\n",
    "            accuracy = metrics.accuracy_score(true,pred)\n",
    "            f1 = metrics.f1_score(true,pred)\n",
    "            recall = metrics.recall_score(true,pred)\n",
    "            roc_auc = metrics.roc_auc_score(true,proba)\n",
    "            scores.append({\n",
    "                'epoch': epoch+1,\n",
    "                'loss': float(loss),\n",
    "                'accuracy': accuracy,\n",
    "                'f1': f1,\n",
    "                'recall': recall,\n",
    "                'roc_auc': roc_auc,\n",
    "            })\n",
    "\n",
    "### Metriques\n",
    "\n",
    "df_scores = pd.DataFrame(scores).set_index('epoch')\n",
    "sns.lineplot(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef791105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7949bc",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508256b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
