{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ec4689",
   "metadata": {},
   "source": [
    "# Plateforme Agnostique de Traitement et d'Analyse des Textes\n",
    "### Carnet d'expérimentation\n",
    "---\n",
    "\n",
    "## Sujet : Pipeline classif infox supervisé sur recueil\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601e626",
   "metadata": {},
   "source": [
    "# Observations et environnement\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525fef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0de4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Geek/Work/Patat\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32256b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d491fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/tmp/230508-RecueilFiltre.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4cc8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recueil = pd.read_csv(filename)\n",
    "df_recueil['paragraphs'] = df_recueil['paragraphs'].apply(ast.literal_eval)\n",
    "df_recueil['abstract'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73a0665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.imp.importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646c4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = patat.imp.importer.Importer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e1ecf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recueil['site'] = df_recueil['url'].apply(imp.get_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c5a544f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#site</th>\n",
       "      <th># article</th>\n",
       "      <th>Site</th>\n",
       "      <th>url</th>\n",
       "      <th>Auteur/trice</th>\n",
       "      <th>Date</th>\n",
       "      <th>Titre</th>\n",
       "      <th>explication</th>\n",
       "      <th>infox</th>\n",
       "      <th>signe</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>tags</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>date_iso</th>\n",
       "      <th>abstract</th>\n",
       "      <th>c_count</th>\n",
       "      <th>p_count</th>\n",
       "      <th>p_size</th>\n",
       "      <th>site</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alnas</td>\n",
       "      <td>https://www.alnas.fr/actualite/communaute/lara...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/10/2022</td>\n",
       "      <td>L’Arabie saoudite organise des célébrations d'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31/10/2022</td>\n",
       "      <td>['ActualitésCommunauté']</td>\n",
       "      <td>[L’Arabie saoudite a organisé un événement pou...</td>\n",
       "      <td>2022-10-31T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>2277</td>\n",
       "      <td>8</td>\n",
       "      <td>284.625000</td>\n",
       "      <td>www.alnas.fr</td>\n",
       "      <td>L’Arabie saoudite organise des célébrations d'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Alnas</td>\n",
       "      <td>https://www.alnas.fr/actualite/en-vrac/quel-ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19/10/2022</td>\n",
       "      <td>« Quel art ! » : un étudiant en droit invente ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19/10/2022</td>\n",
       "      <td>['ActualitésEn vrac']</td>\n",
       "      <td>[Une professeure de droit a partagé sur Twitte...</td>\n",
       "      <td>2022-10-19T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>1683</td>\n",
       "      <td>8</td>\n",
       "      <td>210.375000</td>\n",
       "      <td>www.alnas.fr</td>\n",
       "      <td>« Quel art ! » : un étudiant en droit invente ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alnas</td>\n",
       "      <td>https://www.alnas.fr/actualite/politique/laust...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/10/2022</td>\n",
       "      <td>L’Australie ne reconnaît plus Jérusalem comme ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18/10/2022</td>\n",
       "      <td>['ActualitésPolitique']</td>\n",
       "      <td>[Le gouvernement israélien a qualifié la posit...</td>\n",
       "      <td>2022-10-18T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>2678</td>\n",
       "      <td>15</td>\n",
       "      <td>178.533333</td>\n",
       "      <td>www.alnas.fr</td>\n",
       "      <td>L’Australie ne reconnaît plus Jérusalem comme ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Alnas</td>\n",
       "      <td>https://www.alnas.fr/actualite/communaute/nant...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/10/2022</td>\n",
       "      <td>Nantes : une mère musulmane meurt poignardée e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17/10/2022</td>\n",
       "      <td>['ActualitésCommunauté']</td>\n",
       "      <td>[NANTES – Une enquête pour « homicide volontai...</td>\n",
       "      <td>2022-10-17T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>1792</td>\n",
       "      <td>5</td>\n",
       "      <td>358.400000</td>\n",
       "      <td>www.alnas.fr</td>\n",
       "      <td>Nantes : une mère musulmane meurt poignardée e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alnas</td>\n",
       "      <td>https://www.alnas.fr/actualite/en-vrac/la-fran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2022</td>\n",
       "      <td>La France condamnée pour avoir placé un enfant...</td>\n",
       "      <td>le titre est décalé (donne une impression faus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10/11/2022</td>\n",
       "      <td>['ActualitésEn vrac']</td>\n",
       "      <td>[La Cour européenne des droits de l’Homme (CED...</td>\n",
       "      <td>2022-11-10T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>1482</td>\n",
       "      <td>5</td>\n",
       "      <td>296.400000</td>\n",
       "      <td>www.alnas.fr</td>\n",
       "      <td>La France condamnée pour avoir placé un enfant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>44</td>\n",
       "      <td>617</td>\n",
       "      <td>Wikistrike</td>\n",
       "      <td>https://www.wikistrike.com/2022/10/selon-un-an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/10/2022</td>\n",
       "      <td>Selon un ancien conseiller du Pentagone, les É...</td>\n",
       "      <td>colporte les ragots (vrais ou pas) d'un ex con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Publié par wikistrike.com\\n                   ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Selon un ancien conseiller du Pentagone, les ...</td>\n",
       "      <td>2022-10-04T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>3976</td>\n",
       "      <td>14</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>www.wikistrike.com</td>\n",
       "      <td>Selon un ancien conseiller du Pentagone, les É...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>44</td>\n",
       "      <td>618</td>\n",
       "      <td>Wikistrike</td>\n",
       "      <td>https://www.wikistrike.com/2022/10/la-pologne-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/10/2022</td>\n",
       "      <td>La Pologne s’apprête à s’emparer du territoire...</td>\n",
       "      <td>relai de ragots invérifiés</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Publié par wikistrike.com\\n                   ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[La Pologne se prépare à s’emparer du territoi...</td>\n",
       "      <td>2022-10-31T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>2284</td>\n",
       "      <td>8</td>\n",
       "      <td>285.500000</td>\n",
       "      <td>www.wikistrike.com</td>\n",
       "      <td>La Pologne s’apprête à s’emparer du territoire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>44</td>\n",
       "      <td>619</td>\n",
       "      <td>Wikistrike</td>\n",
       "      <td>https://www.wikistrike.com/2022/11/exclusivite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19/11/2022</td>\n",
       "      <td>Exclusivité WikiStrike: un physicien en colère...</td>\n",
       "      <td>délire total d'un physicien anonyme (ahurissan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Publié par wikistrike.com\\n                   ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Crise énergétique battant son plein,  WikiStr...</td>\n",
       "      <td>2022-11-19T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>27223</td>\n",
       "      <td>27</td>\n",
       "      <td>1008.259259</td>\n",
       "      <td>www.wikistrike.com</td>\n",
       "      <td>Exclusivité WikiStrike: un physicien en colère...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>44</td>\n",
       "      <td>620</td>\n",
       "      <td>Wikistrike</td>\n",
       "      <td>https://www.wikistrike.com/2022/12/zelensky-pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23/12/2023</td>\n",
       "      <td>Zelensky parti demander à papa Biden une aide ...</td>\n",
       "      <td>l'article est vide (même si le titre accuse Ze...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Publié par wikistrike.com\\n                   ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Alors que des milliers d’Ukrainiens meurent, ...</td>\n",
       "      <td>2022-12-23T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>111.400000</td>\n",
       "      <td>www.wikistrike.com</td>\n",
       "      <td>Zelensky parti demander à papa Biden une aide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>44</td>\n",
       "      <td>621</td>\n",
       "      <td>Wikistrike</td>\n",
       "      <td>https://www.wikistrike.com/2023/01/le-chef-du-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/01/2023</td>\n",
       "      <td>Le chef du renseignement iranien assure que la...</td>\n",
       "      <td>long compte rendu d'un interview du chef du re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Publié par wikistrike.com\\n                   ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[par Teheran Times, Le ministre iranien des Re...</td>\n",
       "      <td>2023-01-03T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>7609</td>\n",
       "      <td>24</td>\n",
       "      <td>317.041667</td>\n",
       "      <td>www.wikistrike.com</td>\n",
       "      <td>Le chef du renseignement iranien assure que la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>628 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #site  # article        Site  \\\n",
       "0        1          1       Alnas   \n",
       "1        1          2       Alnas   \n",
       "2        1          3       Alnas   \n",
       "3        1          4       Alnas   \n",
       "4        1          5       Alnas   \n",
       "..     ...        ...         ...   \n",
       "623     44        617  Wikistrike   \n",
       "624     44        618  Wikistrike   \n",
       "625     44        619  Wikistrike   \n",
       "626     44        620  Wikistrike   \n",
       "627     44        621  Wikistrike   \n",
       "\n",
       "                                                   url Auteur/trice  \\\n",
       "0    https://www.alnas.fr/actualite/communaute/lara...          NaN   \n",
       "1    https://www.alnas.fr/actualite/en-vrac/quel-ar...          NaN   \n",
       "2    https://www.alnas.fr/actualite/politique/laust...          NaN   \n",
       "3    https://www.alnas.fr/actualite/communaute/nant...          NaN   \n",
       "4    https://www.alnas.fr/actualite/en-vrac/la-fran...          NaN   \n",
       "..                                                 ...          ...   \n",
       "623  https://www.wikistrike.com/2022/10/selon-un-an...          NaN   \n",
       "624  https://www.wikistrike.com/2022/10/la-pologne-...          NaN   \n",
       "625  https://www.wikistrike.com/2022/11/exclusivite...          NaN   \n",
       "626  https://www.wikistrike.com/2022/12/zelensky-pa...          NaN   \n",
       "627  https://www.wikistrike.com/2023/01/le-chef-du-...          NaN   \n",
       "\n",
       "           Date                                              Titre  \\\n",
       "0    31/10/2022  L’Arabie saoudite organise des célébrations d'...   \n",
       "1    19/10/2022  « Quel art ! » : un étudiant en droit invente ...   \n",
       "2    18/10/2022  L’Australie ne reconnaît plus Jérusalem comme ...   \n",
       "3    17/10/2022  Nantes : une mère musulmane meurt poignardée e...   \n",
       "4    10/11/2022  La France condamnée pour avoir placé un enfant...   \n",
       "..          ...                                                ...   \n",
       "623  04/10/2022  Selon un ancien conseiller du Pentagone, les É...   \n",
       "624  31/10/2022  La Pologne s’apprête à s’emparer du territoire...   \n",
       "625  19/11/2022  Exclusivité WikiStrike: un physicien en colère...   \n",
       "626  23/12/2023  Zelensky parti demander à papa Biden une aide ...   \n",
       "627  03/01/2023  Le chef du renseignement iranien assure que la...   \n",
       "\n",
       "                                           explication  infox  signe  ...  \\\n",
       "0                                                  NaN      0    0.0  ...   \n",
       "1                                                  NaN      0    0.0  ...   \n",
       "2                                                  NaN      0    0.0  ...   \n",
       "3                                                  NaN      0    0.0  ...   \n",
       "4    le titre est décalé (donne une impression faus...      0    0.0  ...   \n",
       "..                                                 ...    ...    ...  ...   \n",
       "623  colporte les ragots (vrais ou pas) d'un ex con...      1    0.0  ...   \n",
       "624                         relai de ragots invérifiés      1    0.0  ...   \n",
       "625  délire total d'un physicien anonyme (ahurissan...      1    0.0  ...   \n",
       "626  l'article est vide (même si le titre accuse Ze...      1    0.0  ...   \n",
       "627  long compte rendu d'un interview du chef du re...      0    0.0  ...   \n",
       "\n",
       "                                                  date  \\\n",
       "0                                           31/10/2022   \n",
       "1                                           19/10/2022   \n",
       "2                                           18/10/2022   \n",
       "3                                           17/10/2022   \n",
       "4                                           10/11/2022   \n",
       "..                                                 ...   \n",
       "623  Publié par wikistrike.com\\n                   ...   \n",
       "624  Publié par wikistrike.com\\n                   ...   \n",
       "625  Publié par wikistrike.com\\n                   ...   \n",
       "626  Publié par wikistrike.com\\n                   ...   \n",
       "627  Publié par wikistrike.com\\n                   ...   \n",
       "\n",
       "                         tags  \\\n",
       "0    ['ActualitésCommunauté']   \n",
       "1       ['ActualitésEn vrac']   \n",
       "2     ['ActualitésPolitique']   \n",
       "3    ['ActualitésCommunauté']   \n",
       "4       ['ActualitésEn vrac']   \n",
       "..                        ...   \n",
       "623                        []   \n",
       "624                        []   \n",
       "625                        []   \n",
       "626                        []   \n",
       "627                        []   \n",
       "\n",
       "                                            paragraphs             date_iso  \\\n",
       "0    [L’Arabie saoudite a organisé un événement pou...  2022-10-31T00:00:00   \n",
       "1    [Une professeure de droit a partagé sur Twitte...  2022-10-19T00:00:00   \n",
       "2    [Le gouvernement israélien a qualifié la posit...  2022-10-18T00:00:00   \n",
       "3    [NANTES – Une enquête pour « homicide volontai...  2022-10-17T00:00:00   \n",
       "4    [La Cour européenne des droits de l’Homme (CED...  2022-11-10T00:00:00   \n",
       "..                                                 ...                  ...   \n",
       "623  [Selon un ancien conseiller du Pentagone, les ...  2022-10-04T00:00:00   \n",
       "624  [La Pologne se prépare à s’emparer du territoi...  2022-10-31T00:00:00   \n",
       "625  [Crise énergétique battant son plein,  WikiStr...  2022-11-19T00:00:00   \n",
       "626  [Alors que des milliers d’Ukrainiens meurent, ...  2022-12-23T00:00:00   \n",
       "627  [par Teheran Times, Le ministre iranien des Re...  2023-01-03T00:00:00   \n",
       "\n",
       "    abstract  c_count  p_count       p_size                site  \\\n",
       "0                2277        8   284.625000        www.alnas.fr   \n",
       "1                1683        8   210.375000        www.alnas.fr   \n",
       "2                2678       15   178.533333        www.alnas.fr   \n",
       "3                1792        5   358.400000        www.alnas.fr   \n",
       "4                1482        5   296.400000        www.alnas.fr   \n",
       "..       ...      ...      ...          ...                 ...   \n",
       "623              3976       14   284.000000  www.wikistrike.com   \n",
       "624              2284        8   285.500000  www.wikistrike.com   \n",
       "625             27223       27  1008.259259  www.wikistrike.com   \n",
       "626               557        5   111.400000  www.wikistrike.com   \n",
       "627              7609       24   317.041667  www.wikistrike.com   \n",
       "\n",
       "                                                  text  \n",
       "0    L’Arabie saoudite organise des célébrations d'...  \n",
       "1    « Quel art ! » : un étudiant en droit invente ...  \n",
       "2    L’Australie ne reconnaît plus Jérusalem comme ...  \n",
       "3    Nantes : une mère musulmane meurt poignardée e...  \n",
       "4    La France condamnée pour avoir placé un enfant...  \n",
       "..                                                 ...  \n",
       "623  Selon un ancien conseiller du Pentagone, les É...  \n",
       "624  La Pologne s’apprête à s’emparer du territoire...  \n",
       "625  Exclusivité WikiStrike: un physicien en colère...  \n",
       "626  Zelensky parti demander à papa Biden une aide ...  \n",
       "627  Le chef du renseignement iranien assure que la...  \n",
       "\n",
       "[628 rows x 52 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recueil[df_recueil['tds']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b548bc6",
   "metadata": {},
   "source": [
    "# Experience\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29618668",
   "metadata": {},
   "source": [
    "## Textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "522b7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(row):\n",
    "    text = row['title']+'\\n\\n'\n",
    "    if row['abstract']:\n",
    "         text = text + row['abstract']+'\\n\\n'\n",
    "    text = text + '\\n\\n'.join(row['paragraphs'])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c9d0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recueil['text'] = df_recueil.apply(get_text,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "883a205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burkini dans les piscines municipales : Pour Darmanin, le choix fait à Grenoble est une « inacceptable provocation communautaire »\n",
      "\n",
      "Source : 20minutes\n",
      "\n",
      "La polémique continue d’enfler autour du burkini. Gérald Darmanin a qualifié mardi d'« inacceptable provocation communautaire » l’autorisation du port de ce maillot de bain dans les piscines municipales de Grenoble.\n",
      "\n",
      "Le conseil municipal de Grenoble, dirigé par le maire écologiste Eric Piolle, a en effet validé lundi par une courte majorité une modification du règlement intérieur des piscines se traduisant par l’autorisation du port du burkini.\n",
      "\n",
      "« M. Piolle, soutien de M. Mélenchon, joue l’inacceptable provocation communautaire, contraire à nos valeurs », a tweeté le ministre de l’Intérieur du gouvernement démissionnaire. « J’ai donné instruction au préfet de déférer en \"déféré laïcité\" la délibération permettant le port du \"Burkini\" et, le cas échéant, d’en demander le retrait », a-t-il ajouté. Le déféré préfectoral s’inscrit dans le cadre du contrôle de légalité des actes des collectivités territoriales.\n",
      "\n",
      "La réponse d’Eric Piolle ne s’est pas fait attendre. « Darmanin, le ministre qui a pour bilan la loi séparatisme, qui trouve Marine Le Pen trop molle, s’insurge des rayons halal et casher des magasins, se permet de donner des leçons ? Relisez la loi de 1905, plutôt que de la tordre », a réagi, également sur Twitter, le maire de Grenoble.\n",
      "\n",
      "Le préfet de l’Isère avait par contre déjà fait savoir dimanche soir, avant la délibération du conseil municipal, qu’il saisirait le tribunal administratif de Grenoble pour bloquer la mesure, sur instruction de Gérald Darmanin. Il devrait pour cela faire appel à une disposition introduite par la loi sur le séparatisme votée en août 2021, qui concerne les actes portant « gravement atteinte au principe de laïcité et de neutralité du service public ». Eric Piolle, qui a invoqué un combat « féministe », de « santé » et de « laïcité », s’est déclaré lundi « ravi que le gouvernement nous attaque », relevant qu’il n’avait « pas attaqué Rennes » lorsque cette ville avait pris une disposition similaire il y a quatre ans.\n",
      "\n",
      "Abonnez-vous sans tarder à notre chaîne Telegram, pour le cas où Dreuz soit censuré, ou son accès coupé. Cliquez ici : Dreuz.Info.Telegram.\n"
     ]
    }
   ],
   "source": [
    "for text in df_recueil['text'].sample(1):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc687995",
   "metadata": {},
   "source": [
    "## Ignore Words / Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f752e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.text\n",
    "import patat.ml.lex_analyser\n",
    "lex = patat.ml.lex_analyser.LexAnalyser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec27bf",
   "metadata": {},
   "source": [
    "### Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd292ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = patat.util.text.preprocess\n",
    "tokenizer = lex.get_lemmas_from_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46fe5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_words = lex.get_df_words(texts= df_recueil['text'],values = df_recueil['infox'].astype(int), preprocessor=preprocessor, tokenizer= tokenizer)\n",
    "### Rare Words\n",
    "for occ_rare in [1,2,3,4,5,6,7]:\n",
    "    df_words['rare_'+str(occ_rare)]=(df_words['count_0']<=occ_rare)&(df_words['count_1']<=occ_rare)\n",
    "### Common words\n",
    "for common_size in [50,80,120,200,500]:\n",
    "    common_0 = df_words.sort_values('count_0',ascending=False).head(common_size).index\n",
    "    common_1 = df_words.sort_values('count_1',ascending=False).head(common_size).index\n",
    "    df_words['common_'+str(common_size)]=(df_words.index.isin(common_0))&(df_words.index.isin(common_1))\n",
    "### Ignore Lemmas\n",
    "ignore_lemmas={\n",
    "    'None' : None,\n",
    "    'small' : list(df_words[df_words['common_80']].index)+list(df_words[df_words['rare_1']].index),\n",
    "    'medium' : list(df_words[df_words['common_80']].index)+list(df_words[df_words['rare_2']].index),\n",
    "    'large' : list(df_words[df_words['common_200']].index)+list(df_words[df_words['rare_5']].index),\n",
    "    'xlarge' : list(df_words[df_words['common_500']].index)+list(df_words[df_words['rare_7']].index),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8030438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count</th>\n",
       "      <th>rare_1</th>\n",
       "      <th>rare_2</th>\n",
       "      <th>rare_3</th>\n",
       "      <th>rare_4</th>\n",
       "      <th>rare_5</th>\n",
       "      <th>rare_6</th>\n",
       "      <th>rare_7</th>\n",
       "      <th>common_50</th>\n",
       "      <th>common_80</th>\n",
       "      <th>common_120</th>\n",
       "      <th>common_200</th>\n",
       "      <th>common_500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>16053</td>\n",
       "      <td>22318</td>\n",
       "      <td>38371</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>9058</td>\n",
       "      <td>12076</td>\n",
       "      <td>21134</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>6711</td>\n",
       "      <td>9591</td>\n",
       "      <td>16302</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>6384</td>\n",
       "      <td>9454</td>\n",
       "      <td>15838</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>les</th>\n",
       "      <td>6110</td>\n",
       "      <td>9761</td>\n",
       "      <td>15871</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iut</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ivano</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ivermectin</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iversen</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>þórólfur</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26206 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            count_0  count_1  count  rare_1  rare_2  rare_3  rare_4  rare_5  \\\n",
       "de            16053    22318  38371   False   False   False   False   False   \n",
       "la             9058    12076  21134   False   False   False   False   False   \n",
       "le             6711     9591  16302   False   False   False   False   False   \n",
       "et             6384     9454  15838   False   False   False   False   False   \n",
       "les            6110     9761  15871   False   False   False   False   False   \n",
       "...             ...      ...    ...     ...     ...     ...     ...     ...   \n",
       "iut               0        1      1    True    True    True    True    True   \n",
       "ivano             0        1      1    True    True    True    True    True   \n",
       "ivermectin        0        2      2   False    True    True    True    True   \n",
       "iversen           0       18     18   False   False   False   False   False   \n",
       "þórólfur          0        1      1    True    True    True    True    True   \n",
       "\n",
       "            rare_6  rare_7  common_50  common_80  common_120  common_200  \\\n",
       "de           False   False       True       True        True        True   \n",
       "la           False   False       True       True        True        True   \n",
       "le           False   False       True       True        True        True   \n",
       "et           False   False       True       True        True        True   \n",
       "les          False   False       True       True        True        True   \n",
       "...            ...     ...        ...        ...         ...         ...   \n",
       "iut           True    True      False      False       False       False   \n",
       "ivano         True    True      False      False       False       False   \n",
       "ivermectin    True    True      False      False       False       False   \n",
       "iversen      False   False      False      False       False       False   \n",
       "þórólfur      True    True      False      False       False       False   \n",
       "\n",
       "            common_500  \n",
       "de                True  \n",
       "la                True  \n",
       "le                True  \n",
       "et                True  \n",
       "les               True  \n",
       "...                ...  \n",
       "iut              False  \n",
       "ivano            False  \n",
       "ivermectin       False  \n",
       "iversen          False  \n",
       "þórólfur         False  \n",
       "\n",
       "[26206 rows x 15 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c561677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'le',\n",
       " 'et',\n",
       " 'les',\n",
       " 'des',\n",
       " 'en',\n",
       " 'un',\n",
       " 'est',\n",
       " 'que',\n",
       " 'du',\n",
       " 'une',\n",
       " 'avoir',\n",
       " 'être',\n",
       " 'pour',\n",
       " 'qui',\n",
       " 'dans',\n",
       " 'il',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'sur',\n",
       " 'ce',\n",
       " 'au',\n",
       " 'plaire',\n",
       " 'faire',\n",
       " 'ne',\n",
       " 'nous',\n",
       " 'qu',\n",
       " 'pouvoir',\n",
       " 'se',\n",
       " 'avec',\n",
       " 'mais',\n",
       " 'tout',\n",
       " 'ou',\n",
       " 'son',\n",
       " 'été',\n",
       " 'aux',\n",
       " 'vous',\n",
       " 'comme',\n",
       " 'cette',\n",
       " 'ces',\n",
       " 'on',\n",
       " 'même',\n",
       " 'elle',\n",
       " 'devoir',\n",
       " 'autre',\n",
       " 'pays',\n",
       " 'leur',\n",
       " 'si',\n",
       " 'je',\n",
       " 'russie',\n",
       " 'ses',\n",
       " 'ils',\n",
       " 'aussi',\n",
       " 'état',\n",
       " 'sa',\n",
       " 'aller',\n",
       " 'bien',\n",
       " 'grand',\n",
       " 'politique',\n",
       " 'sans',\n",
       " 'dire',\n",
       " 'contre',\n",
       " 'france',\n",
       " 'français',\n",
       " 'voir',\n",
       " 'russe',\n",
       " 'premier',\n",
       " 'monde',\n",
       " 'nouveau',\n",
       " 'an',\n",
       " 'depuis',\n",
       " 'entre',\n",
       " 'alors',\n",
       " 'mettre',\n",
       " 'guerre',\n",
       " 'encore',\n",
       " 'après',\n",
       " 'deux',\n",
       " 'uni',\n",
       " 'europe',\n",
       " 'année',\n",
       " 'ukraine',\n",
       " 'cela',\n",
       " 'dernier',\n",
       " 'temps',\n",
       " 'européen',\n",
       " 'non',\n",
       " 'leurs',\n",
       " 'selon',\n",
       " 'prendre',\n",
       " 'tous',\n",
       " 'moins',\n",
       " 'personne',\n",
       " 'dont',\n",
       " 'déclarer',\n",
       " 'gouvernement',\n",
       " 'présider',\n",
       " 'certain',\n",
       " 'lui',\n",
       " 'car',\n",
       " 'ainsi',\n",
       " 'où',\n",
       " 'covid',\n",
       " 'très',\n",
       " 'donner',\n",
       " 'sou',\n",
       " 'américain',\n",
       " 'information',\n",
       " 'soit',\n",
       " 'arme',\n",
       " 'ukrainien',\n",
       " 'otan',\n",
       " 'jour',\n",
       " 'savoir',\n",
       " 'donc',\n",
       " 'national',\n",
       " 'notre',\n",
       " 'homme',\n",
       " 'falloir',\n",
       " 'déjà',\n",
       " 'vouloir',\n",
       " 'aujourd',\n",
       " 'hui',\n",
       " 'également',\n",
       " 'rendre',\n",
       " 'penser',\n",
       " 'comprendre',\n",
       " 'ceux',\n",
       " 'utiliser',\n",
       " 'avant',\n",
       " 'fois',\n",
       " 'cas',\n",
       " 'seul',\n",
       " 'public',\n",
       " 'mondial',\n",
       " 'fin',\n",
       " 'effet',\n",
       " 'article',\n",
       " 'lors',\n",
       " 'enfant',\n",
       " 'question',\n",
       " 'source',\n",
       " 'com',\n",
       " 'vie',\n",
       " 'plusieurs',\n",
       " 'devenir',\n",
       " 'peu',\n",
       " 'toujours',\n",
       " 'million',\n",
       " 'mois',\n",
       " 'média',\n",
       " 'bon',\n",
       " 'militaire',\n",
       " 'raison',\n",
       " 'risque',\n",
       " 'vaccin',\n",
       " 'pendant',\n",
       " 'trouver',\n",
       " 'pain',\n",
       " 'plage',\n",
       " 'danois',\n",
       " 'concession',\n",
       " 'bitcoin',\n",
       " 'kwarteng',\n",
       " 'interviewer',\n",
       " 'assad',\n",
       " 'enceindre',\n",
       " 'écrasant',\n",
       " 'réjoui',\n",
       " 'concitoyen',\n",
       " 'mordre',\n",
       " 'posture',\n",
       " 'jens',\n",
       " 'bis',\n",
       " 'optimiste',\n",
       " 'optimisme',\n",
       " 'géographique',\n",
       " 'questionnaire',\n",
       " 'insupportable',\n",
       " 'anatoly',\n",
       " 'elisabeth_borne',\n",
       " 'anatolie',\n",
       " 'larsonneur',\n",
       " 'comédien',\n",
       " 'renouvellement',\n",
       " 'elizabeth',\n",
       " 'bondir',\n",
       " 'repentance',\n",
       " 'enclin',\n",
       " 'repas',\n",
       " 'traditionaliste',\n",
       " 'vs',\n",
       " 'orage',\n",
       " 'destouches',\n",
       " 'ancrer',\n",
       " 'elonmusk',\n",
       " 'ange',\n",
       " 'vêtir',\n",
       " 'classement',\n",
       " 'civilisationnel',\n",
       " 'entourage',\n",
       " 'respectif',\n",
       " 'dealer',\n",
       " 'commissariat',\n",
       " 'agrément',\n",
       " 'blockchain',\n",
       " 'réparation',\n",
       " 'modernité',\n",
       " 'ressortir',\n",
       " 'pivot',\n",
       " 'pivet',\n",
       " 'circuit',\n",
       " 'conditionnel',\n",
       " 'mobilisations',\n",
       " 'janera',\n",
       " 'condoléance',\n",
       " 'radicalisation',\n",
       " 'aspirer',\n",
       " 'circulant',\n",
       " 'cauchemar',\n",
       " 'angoisse',\n",
       " 'dep',\n",
       " 'pound',\n",
       " 'miroir',\n",
       " 'transformant',\n",
       " 'synthèse',\n",
       " 'concrètement',\n",
       " 'quitte',\n",
       " 'bureaucrate',\n",
       " 'concrétiser',\n",
       " 'impulsion',\n",
       " 'ouvrant',\n",
       " 'inclusion',\n",
       " 'balistique',\n",
       " 'recréer',\n",
       " 'déconnecter',\n",
       " 'today',\n",
       " 'interpellative',\n",
       " 'émir',\n",
       " 'éminemment',\n",
       " 'reconditionnés',\n",
       " 'reconditionner',\n",
       " 'divinité',\n",
       " 'netanyahu',\n",
       " 'émouvoir',\n",
       " 'pleurer',\n",
       " 'éleveur',\n",
       " 'accusatoire',\n",
       " 'boutiquier',\n",
       " 'défiance',\n",
       " 'colline',\n",
       " 'kergoat',\n",
       " 'accélération',\n",
       " 'collectivement',\n",
       " 'inaperçu',\n",
       " 'athée',\n",
       " 'hennebont',\n",
       " 'décaler',\n",
       " 'una',\n",
       " 'interministérielle',\n",
       " 'justesse',\n",
       " 'plénier',\n",
       " 'nouvellement',\n",
       " 'incendier',\n",
       " 'sinistre',\n",
       " 'junior',\n",
       " 'aviser',\n",
       " 'commerçant',\n",
       " 'tiktok',\n",
       " 'rebelle',\n",
       " 'poignarder',\n",
       " 'braun',\n",
       " 'dolines',\n",
       " 'herblain',\n",
       " 'débarquement',\n",
       " 'ravi',\n",
       " 'domestique',\n",
       " 'kaiser',\n",
       " 'avignon',\n",
       " 'émetteur',\n",
       " 'jérôme',\n",
       " 'navigation',\n",
       " 'cascade',\n",
       " 'di',\n",
       " 'mécontent',\n",
       " 'popularité',\n",
       " 'rétroaction',\n",
       " 'dinucci',\n",
       " 'médiatisation',\n",
       " 'méditation',\n",
       " 'mégalithiques',\n",
       " 'amont',\n",
       " 'kong',\n",
       " 'bruire',\n",
       " 'tourne',\n",
       " 'taxer',\n",
       " 'taxi',\n",
       " 'edito',\n",
       " 'rallier',\n",
       " 'différend',\n",
       " 'amuser',\n",
       " 'rembourser',\n",
       " 'ménager',\n",
       " 'bourget',\n",
       " 'démoniaque',\n",
       " 'démolition',\n",
       " 'psilocybine',\n",
       " 'bourreau',\n",
       " 'disproportionner',\n",
       " 'khoi',\n",
       " 'ambigu',\n",
       " 'album',\n",
       " 'délicat',\n",
       " 'navigant',\n",
       " 'hormis',\n",
       " 'bouchet',\n",
       " 'assigner',\n",
       " 'officialiser',\n",
       " 'torre',\n",
       " 'relocalisations',\n",
       " 'harceler',\n",
       " 'métrage',\n",
       " 'hormone',\n",
       " 'boulot',\n",
       " 'révolte',\n",
       " 'damien',\n",
       " 'douloureux',\n",
       " 'lettonie',\n",
       " 'bidule',\n",
       " 'routine',\n",
       " 'pathologique',\n",
       " 'baule',\n",
       " 'ironie',\n",
       " 'cents',\n",
       " 'changeant',\n",
       " 'pécheur',\n",
       " 'arrée',\n",
       " 'centrer',\n",
       " 'arrondissement',\n",
       " 'légalement',\n",
       " 'sauvetage',\n",
       " 'perquisition',\n",
       " 'belliot',\n",
       " 'franco',\n",
       " 'bachar',\n",
       " 'golovko',\n",
       " 'truss',\n",
       " 'fantomatique',\n",
       " 'mathieu',\n",
       " 'automobiliste',\n",
       " 'affichant',\n",
       " 'frontalier',\n",
       " 'convertibilité',\n",
       " 'riyad',\n",
       " 'punir',\n",
       " 'go',\n",
       " 'baccalauréat',\n",
       " 'maréchal',\n",
       " 'chesnot',\n",
       " 'chesnais',\n",
       " 'luxembourg',\n",
       " 'cresson',\n",
       " 'admissible',\n",
       " 'réformer',\n",
       " 'influenceurs',\n",
       " 'malbrunot',\n",
       " 'roosevelt',\n",
       " 'ipg',\n",
       " 'sri',\n",
       " 'peebles',\n",
       " 'apport',\n",
       " 'illusoire',\n",
       " 'celsius',\n",
       " 'librement',\n",
       " 'macronisme',\n",
       " 'style',\n",
       " 'sauli',\n",
       " 'formulation',\n",
       " 'proietti',\n",
       " 'formel',\n",
       " 'forestier',\n",
       " 'rébellion',\n",
       " 'péril',\n",
       " 'yannick',\n",
       " 'réclamation',\n",
       " 'aîné',\n",
       " 'manlio',\n",
       " 'bfm',\n",
       " 'beyond',\n",
       " 'malheureux',\n",
       " 'cousin',\n",
       " 'roman',\n",
       " 'autoroute',\n",
       " 'subsister',\n",
       " 'celera',\n",
       " 'spot',\n",
       " 'invitation',\n",
       " 'stop',\n",
       " 'georges',\n",
       " 'écolier',\n",
       " 'rhône',\n",
       " 'surseoir',\n",
       " 'loudéac',\n",
       " 'loup',\n",
       " 'exploit',\n",
       " 'ribera',\n",
       " 'impasse',\n",
       " 'congé',\n",
       " 'quai',\n",
       " 'ruffin',\n",
       " 'contraste',\n",
       " 'régir',\n",
       " 'exorbitant',\n",
       " 'bionique',\n",
       " 'confort',\n",
       " 'régulation',\n",
       " 'quatennens',\n",
       " 'adhérent',\n",
       " 'messe',\n",
       " 'galic',\n",
       " 'règlementations',\n",
       " 'livry',\n",
       " 'régularité',\n",
       " 'prospérer',\n",
       " 'aval',\n",
       " 'inhumain',\n",
       " 'lc',\n",
       " 'célébration',\n",
       " 'surcroît',\n",
       " 'ucl',\n",
       " 'bechet',\n",
       " 'extinction',\n",
       " 'priser',\n",
       " 'cruel',\n",
       " 'mccarthy',\n",
       " 'lecourrier',\n",
       " 'mayotte',\n",
       " 'lega',\n",
       " 'souterrain',\n",
       " 'croître',\n",
       " 'réinformation',\n",
       " 'privilège',\n",
       " 'gouffre',\n",
       " 'meat',\n",
       " 'loïg',\n",
       " 'extrémité',\n",
       " 'funeste',\n",
       " 'souhait',\n",
       " 'goutte',\n",
       " 'mediterranean',\n",
       " 'biodiversité',\n",
       " 'préalablement',\n",
       " 'mearsheimer',\n",
       " 'funérailles',\n",
       " 'revers',\n",
       " 'cambriolage',\n",
       " 'alcoolique',\n",
       " 'ray',\n",
       " 'dispute',\n",
       " 'raymond',\n",
       " 'dissidence',\n",
       " 'honteux',\n",
       " 'phare',\n",
       " 'coronariens',\n",
       " 'imbécile',\n",
       " 'audace',\n",
       " 'sauter',\n",
       " 'téléphonie',\n",
       " 'contraignant',\n",
       " 'coronarien',\n",
       " 'savant',\n",
       " 'ravage',\n",
       " 'titanic',\n",
       " 'coordination',\n",
       " 'rattraper',\n",
       " 'objectivité',\n",
       " 'rattachement',\n",
       " 'contrepartie',\n",
       " 'téléphérique',\n",
       " 'dolmen',\n",
       " 'ratifier',\n",
       " 'observatoire',\n",
       " 'émergentes',\n",
       " 'douarnenez',\n",
       " 'hlm',\n",
       " 'imiter',\n",
       " 'briand',\n",
       " 'juguler',\n",
       " 'néant',\n",
       " 'vieillard',\n",
       " 'contractuel',\n",
       " 'all',\n",
       " 'érythréens',\n",
       " 'sauvegarde',\n",
       " 'diverger',\n",
       " 'tisser',\n",
       " 'rassuriste',\n",
       " 'touquet',\n",
       " 'disposant',\n",
       " 'odieux',\n",
       " 'créneau',\n",
       " 'parking',\n",
       " 'dense',\n",
       " 'samarcande',\n",
       " 'oslo',\n",
       " 'sicile',\n",
       " 'bénéficiaire',\n",
       " 'virage',\n",
       " 'sarah',\n",
       " 'trotskiste',\n",
       " 'jardin',\n",
       " 'islamisation',\n",
       " 'islamo',\n",
       " 'cul',\n",
       " 'orwell',\n",
       " 'trans',\n",
       " 'atout',\n",
       " 'participe',\n",
       " 'croisière',\n",
       " 'participatif',\n",
       " 'humiliation',\n",
       " 'atroce',\n",
       " 'salvatore',\n",
       " 'partenariats',\n",
       " 'atrocité',\n",
       " 'afflux',\n",
       " 'trancher',\n",
       " 'islamophobie',\n",
       " 'transhumanisme',\n",
       " 'quiet',\n",
       " 'hypocrite',\n",
       " 'quimperlé',\n",
       " 'hypothécaire',\n",
       " 'itt',\n",
       " 'hâte',\n",
       " 'byoblu',\n",
       " 'hébreu',\n",
       " 'tricher',\n",
       " 'travis',\n",
       " 'tropique',\n",
       " 'cuvillier',\n",
       " 'parapluie',\n",
       " 'bénir',\n",
       " 'otzma',\n",
       " 'parade',\n",
       " 'hôtellerie',\n",
       " 'triomphe',\n",
       " 'quantum',\n",
       " 'short',\n",
       " 'humide',\n",
       " 'virologique',\n",
       " 'offrant',\n",
       " 'offusquer',\n",
       " 'adverse',\n",
       " 'païen',\n",
       " 'ille',\n",
       " 'payant',\n",
       " 'cotisation',\n",
       " 'silicon',\n",
       " 'tunnel',\n",
       " 'couronner',\n",
       " 'coutume',\n",
       " 'salen',\n",
       " 'palestiniennes',\n",
       " 'éroder',\n",
       " 'correspondant',\n",
       " 'yaël',\n",
       " 'corriger',\n",
       " 'dispac',\n",
       " 'cortège',\n",
       " 'coréen',\n",
       " 'coter',\n",
       " 'tormenen',\n",
       " 'oeuvrer',\n",
       " 'péninsule',\n",
       " 'peiner',\n",
       " 'peindre',\n",
       " 'hot',\n",
       " 'ralentissement',\n",
       " 'passible',\n",
       " 'pêche',\n",
       " 'optimal',\n",
       " 'qataris',\n",
       " 'optimiser',\n",
       " 'bac',\n",
       " 'huer',\n",
       " 'ajout',\n",
       " 'parution',\n",
       " 'orbite',\n",
       " 'traditionnellement',\n",
       " 'oppression',\n",
       " 'jn',\n",
       " 'tournage',\n",
       " 'différemment',\n",
       " 'diffuseur',\n",
       " 'touristique',\n",
       " 'bruxellois',\n",
       " 'bruyant',\n",
       " 'pathogénicité',\n",
       " 'diam',\n",
       " 'tousser',\n",
       " 'railler',\n",
       " 'diable',\n",
       " 'protagoniste',\n",
       " 'méditer',\n",
       " 'baller',\n",
       " 'f_desouche',\n",
       " 'réfractaire',\n",
       " 'mauranne',\n",
       " 'googliath',\n",
       " 'artistique',\n",
       " 'mcconnell',\n",
       " 'mcdonald',\n",
       " 'ringard',\n",
       " 'zombie',\n",
       " 'rigoureux',\n",
       " 'medef',\n",
       " 'bastion',\n",
       " 'gouvernant',\n",
       " 'goûter',\n",
       " 'gpa',\n",
       " 'exportateur',\n",
       " 'rice',\n",
       " 'rituel',\n",
       " 'favorablement',\n",
       " 'marian',\n",
       " 'robe',\n",
       " 'bienfait',\n",
       " 'échéant',\n",
       " 'éclair',\n",
       " 'apaiser',\n",
       " 'gnl',\n",
       " 'superpuissance',\n",
       " 'fatal',\n",
       " 'rive',\n",
       " 'soviet',\n",
       " 'éclat',\n",
       " 'support',\n",
       " 'bilatérales',\n",
       " 'fantasme',\n",
       " 'explicitement',\n",
       " 'anticipation',\n",
       " 'souiller',\n",
       " 'graver',\n",
       " 'gravitationnel',\n",
       " 'midterms',\n",
       " 'anticor',\n",
       " 'eurodéputé',\n",
       " 'lapid',\n",
       " 'retourne',\n",
       " 'lannion',\n",
       " 'minimal',\n",
       " 'essor',\n",
       " 'espérance',\n",
       " 'minutieux',\n",
       " 'syndical',\n",
       " 'laura',\n",
       " 'réguler',\n",
       " 'explicite',\n",
       " 'exhorter',\n",
       " 'expatrié',\n",
       " 'gradé',\n",
       " 'meridian',\n",
       " 'merveille',\n",
       " 'merveilleux',\n",
       " 'exigeant',\n",
       " 'exhaustif',\n",
       " 'exergue',\n",
       " 'exempter',\n",
       " 'antimissile',\n",
       " 'excéder',\n",
       " 'grandeur',\n",
       " 'lauréat',\n",
       " 'excuser',\n",
       " 'globalisme',\n",
       " 'fi',\n",
       " 'frédéric',\n",
       " 'gazier',\n",
       " 'lumieresurgaia',\n",
       " 'liquéfier',\n",
       " 'belligérant',\n",
       " 'ly',\n",
       " 'stratégiquement',\n",
       " 'frappant',\n",
       " 'franklin',\n",
       " 'légalisation',\n",
       " 'francois',\n",
       " 'bennett',\n",
       " 'benoît',\n",
       " 'wikipedia',\n",
       " 'légitimement',\n",
       " 'stresser',\n",
       " 'rte',\n",
       " 'lugan',\n",
       " 'fragilité',\n",
       " 'gaspillage',\n",
       " 'gar',\n",
       " 'gamin',\n",
       " 'lockyer',\n",
       " 'galerie',\n",
       " 'londonien',\n",
       " 'gage',\n",
       " 'longévité',\n",
       " 'fréquenter',\n",
       " 'live',\n",
       " 'litzmannstadt',\n",
       " 'lovecraft',\n",
       " 'funéraire',\n",
       " 'belenet',\n",
       " 'rude',\n",
       " 'armoire',\n",
       " 'archipel',\n",
       " 'ar',\n",
       " 'gilead',\n",
       " 'spécialement',\n",
       " 'arrogance',\n",
       " 'wokisme',\n",
       " 'applique',\n",
       " 'submerger',\n",
       " 'flickr',\n",
       " 'malsain',\n",
       " 'romain',\n",
       " 'récidive',\n",
       " 'mandante',\n",
       " 'mandater',\n",
       " 'récipient',\n",
       " 'spiritualité',\n",
       " 'glissement',\n",
       " 'ficeler',\n",
       " 'flynn',\n",
       " 'fléchir',\n",
       " 'arrangement',\n",
       " 'fouille',\n",
       " 'fouché',\n",
       " 'squelette',\n",
       " 'fortiori',\n",
       " 'berlioz',\n",
       " 'mag',\n",
       " 'maga',\n",
       " 'maghreb',\n",
       " 'footprint',\n",
       " 'rotation',\n",
       " 'arranger',\n",
       " 'fn',\n",
       " 'arrestation',\n",
       " 'fonctionnalité',\n",
       " 'appréhender',\n",
       " 'approvisionner',\n",
       " 'spécialité',\n",
       " 'focaliser',\n",
       " 'landerneau',\n",
       " 'esd',\n",
       " 'khoury',\n",
       " 'dénombrer',\n",
       " 'dénigrer',\n",
       " 'napoléon',\n",
       " 'regret',\n",
       " 'bourguignon',\n",
       " 'déléguer',\n",
       " 'assouplir',\n",
       " 'délibération',\n",
       " 'khashoggi',\n",
       " 'déjouer',\n",
       " 'déjeuner',\n",
       " 'déguiser',\n",
       " 'tes',\n",
       " 'défunt',\n",
       " 'bouton',\n",
       " 'najatvb',\n",
       " 'nafeez',\n",
       " 'hbj',\n",
       " 'détresse',\n",
       " 'électorat',\n",
       " 'détente',\n",
       " 'assets',\n",
       " 'déstabiliser',\n",
       " 'médiéval',\n",
       " 'mélanie',\n",
       " 'déshumaniser',\n",
       " 'dépistage',\n",
       " 'tempête',\n",
       " 'bouddha',\n",
       " 'déroulement',\n",
       " 'métaverse',\n",
       " 'boue',\n",
       " 'socialisme',\n",
       " 'métropole',\n",
       " 'votant',\n",
       " 'boulevard',\n",
       " 'redressement',\n",
       " 'kenya',\n",
       " 'duo',\n",
       " 'noble',\n",
       " 'thomin',\n",
       " 'nocif',\n",
       " 'alléger',\n",
       " 'baltic',\n",
       " 'durablement',\n",
       " 'nordique',\n",
       " 'nostalgie',\n",
       " 'think',\n",
       " 'duel',\n",
       " 'notifier',\n",
       " 'théorique',\n",
       " 'sagittaire',\n",
       " 'november',\n",
       " 'redon',\n",
       " 'netherlands',\n",
       " 'nettoyage',\n",
       " 'kelly',\n",
       " 'décrier',\n",
       " 'altman',\n",
       " 'recouvert',\n",
       " 'kart',\n",
       " 'kalanick',\n",
       " 'reconsidérer',\n",
       " 'décharger',\n",
       " 'élucid',\n",
       " 'recommencer',\n",
       " 'thermomix',\n",
       " 'niinistö',\n",
       " 'déborder',\n",
       " 'rechange',\n",
       " 'rétorquer',\n",
       " 'réticent',\n",
       " 'végan',\n",
       " 'séparatisme',\n",
       " 'enrichi',\n",
       " 'ladj',\n",
       " 'requête',\n",
       " 'répondant',\n",
       " 'guise',\n",
       " 'monarchie',\n",
       " 'anguille',\n",
       " 'endiguer',\n",
       " 'bardella',\n",
       " 'encourir',\n",
       " 'encercler',\n",
       " 'reproche',\n",
       " 'kwasi',\n",
       " 'emr',\n",
       " 'guerrand',\n",
       " 'répertoire',\n",
       " 'anodin',\n",
       " 'mitch',\n",
       " 'mitchell',\n",
       " 'mitiger',\n",
       " 'systémiques',\n",
       " 'groupement',\n",
       " 'sébastien',\n",
       " 'lamballe',\n",
       " 'répercuter',\n",
       " 'édile',\n",
       " 'mobilité',\n",
       " 'sécuritaire',\n",
       " 'grumberg',\n",
       " 'envergure',\n",
       " 'entériner',\n",
       " 'édith',\n",
       " 'répercussion',\n",
       " 'édouard',\n",
       " 'molac',\n",
       " 'réservoir',\n",
       " 'andy',\n",
       " 'mortier',\n",
       " 'kosovo',\n",
       " 'vrbpac',\n",
       " 'ha',\n",
       " 'murphy',\n",
       " 'soigneusement',\n",
       " 'muser',\n",
       " 'mutilation',\n",
       " 'economie',\n",
       " 'tchèque',\n",
       " 'ecologiste',\n",
       " 'andrei',\n",
       " 'renaudie',\n",
       " 'echos',\n",
       " 'tebboune',\n",
       " 'myriam',\n",
       " 'techno',\n",
       " 'mystique',\n",
       " 'soixante',\n",
       " 'effrayer',\n",
       " 'effroyable',\n",
       " 'tatar',\n",
       " 'kurzweil',\n",
       " 'kurdistan',\n",
       " 'solidité',\n",
       " 'andersson',\n",
       " 'repli',\n",
       " 'tandem',\n",
       " 'emblée',\n",
       " 'tandonnet',\n",
       " 'généralisation',\n",
       " 'reparler',\n",
       " 'solidarite',\n",
       " 'muet',\n",
       " 'renouvelables',\n",
       " 'renouer',\n",
       " 'tarif',\n",
       " 'kretinsky',\n",
       " 'eimer',\n",
       " 'putaclicks',\n",
       " 'caricature',\n",
       " 'incarnation',\n",
       " 'ypg',\n",
       " 'plume',\n",
       " 'pluralisme',\n",
       " 'conspirationnistes',\n",
       " 'accroche',\n",
       " 'coercition',\n",
       " 'addition',\n",
       " 'cheffe',\n",
       " 'pipe',\n",
       " 'autrichien',\n",
       " 'prêcher',\n",
       " 'catégoriquement',\n",
       " 'carney',\n",
       " 'inconscient',\n",
       " 'prochainement',\n",
       " 'commercialisation',\n",
       " 'commémorer',\n",
       " 'préconisations',\n",
       " 'ploërmel',\n",
       " 'abbé',\n",
       " 'projecteur',\n",
       " 'complexité',\n",
       " 'populiste',\n",
       " 'prouesse',\n",
       " 'coail',\n",
       " 'conforter',\n",
       " 'var',\n",
       " 'instituer',\n",
       " 'pontivy',\n",
       " 'academy',\n",
       " 'intifada',\n",
       " 'vertical',\n",
       " 'primordial',\n",
       " 'interner',\n",
       " 'cohérence',\n",
       " 'secouer',\n",
       " 'privation',\n",
       " 'chirac',\n",
       " 'pie',\n",
       " 'valet',\n",
       " 'colon',\n",
       " 'inertie',\n",
       " 'choeur',\n",
       " 'politics',\n",
       " 'collomb',\n",
       " 'conservatisme',\n",
       " 'intolérable',\n",
       " 'coller',\n",
       " 'indéniable',\n",
       " 'colorado',\n",
       " 'valley',\n",
       " 'étranglement',\n",
       " 'incessant',\n",
       " 'pull',\n",
       " 'confisquer',\n",
       " 'piquer',\n",
       " 'scandinave',\n",
       " 'poing',\n",
       " 'uberfiles',\n",
       " 'abouti',\n",
       " 'insalubre',\n",
       " 'valir',\n",
       " 'col',\n",
       " 'accumulation',\n",
       " 'yehudit',\n",
       " 'inconciliable',\n",
       " 'validité',\n",
       " 'carrément',\n",
       " 'insoutenable',\n",
       " 'projeter',\n",
       " 'conférer',\n",
       " 'intervalle',\n",
       " 'camus',\n",
       " 'instrumentalisation',\n",
       " 'consécutif',\n",
       " 'confédération',\n",
       " 'plafond',\n",
       " 'portraire',\n",
       " 'inhérent',\n",
       " 'centriste',\n",
       " 'propice',\n",
       " 'clause',\n",
       " 'indigner',\n",
       " 'postal',\n",
       " 'plaidoyer',\n",
       " 'conjoindre',\n",
       " 'clientèle',\n",
       " 'conjuguer',\n",
       " 'indigne',\n",
       " 'clément',\n",
       " 'yorker',\n",
       " 'accomplir',\n",
       " 'préfète',\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_lemmas['large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71e8ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_text = ' '.join(ignore_lemmas['small'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c542766a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12270"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(sw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eb7014b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12270"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ignore_lemmas['small'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ced58826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ignore_lemmas['small'])-set(tokenizer(sw_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "100f7f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['équivaloir']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('équivaloir')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49ac5a",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b51aa743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aboutir', 'affilier', 'alambiquer', 'ambitieux', 'boire', 'bouillir', 'climatiser', 'commercer', 'coordonner', 'croire', 'divertir', 'décombrer', 'décrépir', 'déplaire', 'désordonner', 'florir', 'grandir', 'inclure', 'intégrer', 'joindre', 'matcher', 'maudire', 'menacer', 'mol', 'mou', 'nuire', 'obéir', 'oxygéner', 'pondérer', 'presser', 'précieux', 'présumer', 'recroître', 'saisir', 'satisfaire', 'standardiser', 'structurer', 'subventionner', 'suivre', 'tracter', 'urger', 'vieillir', 'vrombir', 'émerger', 'énoncer', 'équivaloir'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.8914748292436125, 'f1': 0.7777777777777777, 'accuracy': 0.8095238095238095, 'recall': 0.711864406779661, 'log_loss': 6.865457788403268, 'false_positive': 0.05555555555555555, 'false_negative': 0.1349206349206349}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aboutir', 'affilier', 'alambiquer', 'ambitieux', 'boire', 'bouillir', 'climatiser', 'commercer', 'coordonner', 'croire', 'divertir', 'décombrer', 'décrépir', 'déplaire', 'désordonner', 'florir', 'grandir', 'inclure', 'intégrer', 'joindre', 'matcher', 'maudire', 'menacer', 'mol', 'mou', 'nuire', 'obéir', 'oxygéner', 'pondérer', 'presser', 'précieux', 'présumer', 'recroître', 'saisir', 'satisfaire', 'standardiser', 'structurer', 'subventionner', 'suivre', 'tracter', 'urger', 'vieillir', 'vrombir', 'émerger', 'énoncer', 'équivaloir'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.9028585884138629, 'f1': 0.8173913043478261, 'accuracy': 0.8333333333333334, 'recall': 0.7966101694915254, 'log_loss': 6.007275564852859, 'false_positive': 0.07142857142857142, 'false_negative': 0.09523809523809523}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "tokenizer = lex.get_lemmas_from_text\n",
    "\n",
    "logreg = LogisticRegression(C=1, random_state=random_state, solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "neuralnet = MLPClassifier(alpha=1, max_iter=1000, hidden_layer_sizes=(8,8), random_state=random_state)\n",
    "\n",
    "pipelineLR = Pipeline(steps = [\n",
    "    ('vectorizer',TfidfVectorizer(preprocessor=preprocessor, tokenizer=tokenizer, stop_words=ignore_lemmas['large'])), \n",
    "    ('classifier',logreg)\n",
    "                  ])\n",
    "\n",
    "pipelineMLPC = Pipeline(steps = [\n",
    "    ('vectorizer',TfidfVectorizer(preprocessor=preprocessor, tokenizer=tokenizer, stop_words=ignore_lemmas['large'])), \n",
    "    ('classifier',neuralnet)\n",
    "                  ])\n",
    "\n",
    "train_size = 0.80\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_recueil['text'], df_recueil['infox'], train_size=train_size, random_state=random_state)\n",
    "\n",
    "for pipeline in [pipelineLR,pipelineMPLC]:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_preds = pipeline.predict(X_test)\n",
    "    y_probas = pipeline.predict_proba(X_test)\n",
    "\n",
    "    results = {}\n",
    "    results['roc_auc'] = metrics.roc_auc_score(y_test, y_probas[:, 1])\n",
    "    results['f1']=metrics.f1_score(y_test, y_preds)\n",
    "    results['accuracy']=metrics.accuracy_score(y_test, y_preds)\n",
    "    results['recall']=metrics.recall_score(y_test, y_preds)\n",
    "    results['log_loss'] = metrics.log_loss(y_test, y_preds)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_preds,normalize='all')\n",
    "    results['false_positive']=cnf_matrix[0,1]\n",
    "    results['false_negative']=cnf_matrix[1,0]\n",
    "\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298b2bd",
   "metadata": {},
   "source": [
    "## Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4b1ba2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "X = df_recueil['text']\n",
    "y = df_recueil['infox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineLR = Pipeline(steps = [\n",
    "    ('vectorizer',TfidfVectorizer(preprocessor=preprocessor, tokenizer=tokenizer, stop_words=ignore_lemmas['small'])), \n",
    "    ('classifier',logreg)\n",
    "                  ])\n",
    "\n",
    "pipelineMLPC = Pipeline(steps = [\n",
    "    ('vectorizer',TfidfVectorizer(preprocessor=preprocessor, tokenizer=None, stop_words=None)), \n",
    "    ('classifier',neuralnet)\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3733efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aboutir', 'alambiquer', 'ambitieux', 'bouillir', 'breveter', 'bruire', 'bénir', 'climatiser', 'cuire', 'divertir', 'décrépir', 'déplaire', 'désordonner', 'instruire', 'matcher', 'maudire', 'mol', 'mou', 'muqueux', 'obéir', 'oxygéner', 'pondérer', 'saisir', 'satisfaire', 'spécifier', 'subventionner', 'vieillir', 'vrombir'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aboutir', 'alambiquer', 'ambitieux', 'bouillir', 'breveter', 'bruire', 'bénir', 'climatiser', 'cuire', 'divertir', 'décrépir', 'déplaire', 'désordonner', 'instruire', 'matcher', 'maudire', 'mol', 'mou', 'muqueux', 'obéir', 'oxygéner', 'pondérer', 'saisir', 'satisfaire', 'spécifier', 'subventionner', 'vieillir', 'vrombir'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aboutir', 'alambiquer', 'ambitieux', 'bouillir', 'breveter', 'bruire', 'bénir', 'climatiser', 'cuire', 'divertir', 'décrépir', 'déplaire', 'désordonner', 'instruire', 'matcher', 'maudire', 'mol', 'mou', 'muqueux', 'obéir', 'oxygéner', 'pondérer', 'saisir', 'satisfaire', 'spécifier', 'subventionner', 'vieillir', 'vrombir'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aboutir', 'alambiquer', 'ambitieux', 'bouillir', 'breveter', 'bruire', 'bénir', 'climatiser', 'cuire', 'divertir', 'décrépir', 'déplaire', 'désordonner', 'instruire', 'matcher', 'maudire', 'mol', 'mou', 'muqueux', 'obéir', 'oxygéner', 'pondérer', 'saisir', 'satisfaire', 'spécifier', 'subventionner', 'vieillir', 'vrombir'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aboutir', 'alambiquer', 'ambitieux', 'bouillir', 'breveter', 'bruire', 'bénir', 'climatiser', 'cuire', 'divertir', 'décrépir', 'déplaire', 'désordonner', 'instruire', 'matcher', 'maudire', 'mol', 'mou', 'muqueux', 'obéir', 'oxygéner', 'pondérer', 'saisir', 'satisfaire', 'spécifier', 'subventionner', 'vieillir', 'vrombir'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.36175489, 0.34003305, 0.36613297, 0.38266587, 0.33973193]),\n",
       " 'score_time': array([0.16125393, 0.12684703, 0.17539096, 0.14286113, 0.14137077]),\n",
       " 'test_roc_auc': array([0.76590909, 0.83333333, 0.9270202 , 0.63020031, 0.64997432]),\n",
       " 'test_f1': array([0.6       , 0.79646018, 0.85483871, 0.53571429, 0.64      ]),\n",
       " 'test_accuracy': array([0.71428571, 0.81746032, 0.85714286, 0.584     , 0.64      ]),\n",
       " 'test_recall': array([0.45      , 0.75      , 0.88333333, 0.50847458, 0.6779661 ])}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipelineLR\n",
    "scores = cross_validate(classifier, X, y, cv=5,scoring=('roc_auc','f1','accuracy','recall'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ee829",
   "metadata": {},
   "source": [
    "## Entrainement sur tout le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78f95e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/p311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aboutir', 'affilier', 'alambiquer', 'ambitieux', 'boire', 'bouillir', 'climatiser', 'commercer', 'coordonner', 'croire', 'divertir', 'décombrer', 'décrépir', 'déplaire', 'désordonner', 'florir', 'grandir', 'inclure', 'intégrer', 'joindre', 'matcher', 'maudire', 'menacer', 'mol', 'mou', 'nuire', 'obéir', 'oxygéner', 'pondérer', 'presser', 'précieux', 'présumer', 'recroître', 'saisir', 'satisfaire', 'standardiser', 'structurer', 'subventionner', 'suivre', 'tracter', 'urger', 'vieillir', 'vrombir', 'émerger', 'énoncer', 'équivaloir'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 TfidfVectorizer(preprocessor=&lt;function preprocess at 0x146f28180&gt;,\n",
       "                                 stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;le&#x27;, &#x27;et&#x27;, &#x27;les&#x27;,\n",
       "                                             &#x27;des&#x27;, &#x27;en&#x27;, &#x27;un&#x27;, &#x27;est&#x27;, &#x27;que&#x27;,\n",
       "                                             &#x27;du&#x27;, &#x27;une&#x27;, &#x27;avoir&#x27;, &#x27;être&#x27;,\n",
       "                                             &#x27;pour&#x27;, &#x27;qui&#x27;, &#x27;dans&#x27;, &#x27;il&#x27;, &#x27;par&#x27;,\n",
       "                                             &#x27;pas&#x27;, &#x27;sur&#x27;, &#x27;ce&#x27;, &#x27;au&#x27;, &#x27;plaire&#x27;,\n",
       "                                             &#x27;faire&#x27;, &#x27;ne&#x27;, &#x27;nous&#x27;, &#x27;qu&#x27;,\n",
       "                                             &#x27;pouvoir&#x27;, &#x27;se&#x27;, ...],\n",
       "                                 tokenizer=&lt;bound method LexAnalyser.get_lemmas_from_text of &lt;patat.ml.lex_analyser.LexAnalyser object at 0x1629e9690&gt;&gt;)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(C=1, max_iter=1000, multi_class=&#x27;ovr&#x27;,\n",
       "                                    random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 TfidfVectorizer(preprocessor=&lt;function preprocess at 0x146f28180&gt;,\n",
       "                                 stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;le&#x27;, &#x27;et&#x27;, &#x27;les&#x27;,\n",
       "                                             &#x27;des&#x27;, &#x27;en&#x27;, &#x27;un&#x27;, &#x27;est&#x27;, &#x27;que&#x27;,\n",
       "                                             &#x27;du&#x27;, &#x27;une&#x27;, &#x27;avoir&#x27;, &#x27;être&#x27;,\n",
       "                                             &#x27;pour&#x27;, &#x27;qui&#x27;, &#x27;dans&#x27;, &#x27;il&#x27;, &#x27;par&#x27;,\n",
       "                                             &#x27;pas&#x27;, &#x27;sur&#x27;, &#x27;ce&#x27;, &#x27;au&#x27;, &#x27;plaire&#x27;,\n",
       "                                             &#x27;faire&#x27;, &#x27;ne&#x27;, &#x27;nous&#x27;, &#x27;qu&#x27;,\n",
       "                                             &#x27;pouvoir&#x27;, &#x27;se&#x27;, ...],\n",
       "                                 tokenizer=&lt;bound method LexAnalyser.get_lemmas_from_text of &lt;patat.ml.lex_analyser.LexAnalyser object at 0x1629e9690&gt;&gt;)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(C=1, max_iter=1000, multi_class=&#x27;ovr&#x27;,\n",
       "                                    random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(preprocessor=&lt;function preprocess at 0x146f28180&gt;,\n",
       "                stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;le&#x27;, &#x27;et&#x27;, &#x27;les&#x27;, &#x27;des&#x27;, &#x27;en&#x27;, &#x27;un&#x27;,\n",
       "                            &#x27;est&#x27;, &#x27;que&#x27;, &#x27;du&#x27;, &#x27;une&#x27;, &#x27;avoir&#x27;, &#x27;être&#x27;, &#x27;pour&#x27;,\n",
       "                            &#x27;qui&#x27;, &#x27;dans&#x27;, &#x27;il&#x27;, &#x27;par&#x27;, &#x27;pas&#x27;, &#x27;sur&#x27;, &#x27;ce&#x27;,\n",
       "                            &#x27;au&#x27;, &#x27;plaire&#x27;, &#x27;faire&#x27;, &#x27;ne&#x27;, &#x27;nous&#x27;, &#x27;qu&#x27;,\n",
       "                            &#x27;pouvoir&#x27;, &#x27;se&#x27;, ...],\n",
       "                tokenizer=&lt;bound method LexAnalyser.get_lemmas_from_text of &lt;patat.ml.lex_analyser.LexAnalyser object at 0x1629e9690&gt;&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=1000, multi_class=&#x27;ovr&#x27;, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(preprocessor=<function preprocess at 0x146f28180>,\n",
       "                                 stop_words=['de', 'la', 'le', 'et', 'les',\n",
       "                                             'des', 'en', 'un', 'est', 'que',\n",
       "                                             'du', 'une', 'avoir', 'être',\n",
       "                                             'pour', 'qui', 'dans', 'il', 'par',\n",
       "                                             'pas', 'sur', 'ce', 'au', 'plaire',\n",
       "                                             'faire', 'ne', 'nous', 'qu',\n",
       "                                             'pouvoir', 'se', ...],\n",
       "                                 tokenizer=<bound method LexAnalyser.get_lemmas_from_text of <patat.ml.lex_analyser.LexAnalyser object at 0x1629e9690>>)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1, max_iter=1000, multi_class='ovr',\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps = [\n",
    "    ('vectorizer',TfidfVectorizer(preprocessor=preprocessor, tokenizer=tokenizer, stop_words=ignore_lemmas['large'])), \n",
    "    ('classifier',logreg)\n",
    "                  ])\n",
    "\n",
    "pipeline.fit(df_recueil['text'], df_recueil['infox'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76996d3a",
   "metadata": {},
   "source": [
    "# Sauvegarde des résultats\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb76357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "patat.util.file.pickle_save(pipelineLR,'data/tmp/230425-LogRegInfox.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patat.util.file.pickle_save(pipelineMPLC,'data/tmp/230425-MPLCInfox.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7949bc",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360655",
   "metadata": {},
   "source": [
    "# Bricolages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44f2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
