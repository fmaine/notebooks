{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a8b7b9",
   "metadata": {},
   "source": [
    "# Plateforme Agnostique de Traitement et d'Analyse des Textes\n",
    "### Carnet d'expérimentation\n",
    "---\n",
    "\n",
    "## Sujet : Predictions Infox - Comparaison Bag of Words\n",
    "\n",
    "---\n",
    "\n",
    "### Conseils JW\n",
    "- XGBoost pour données structurées\n",
    "- Spacy\n",
    "- Fasttext avec api python : https://fasttext.cc/docs/en/python-module.html\n",
    "- Comment fusionner les vecteurs de mots : Doc2Vec\n",
    "- Réseau de neurones : faire petit, metrique AUC\n",
    "- Word Embedings : https://fasttext.cc/docs/en/crawl-vectors.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601e626",
   "metadata": {},
   "source": [
    "# Observations et environnement\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d0de4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fm/Desktop/Work/Patat\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32256b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3925385",
   "metadata": {},
   "source": [
    "## Paramètres globaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76da150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37727b5",
   "metadata": {},
   "source": [
    "## Données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32409d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_recueil = pd.read_csv('data/demo/221123-TextInfox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63370cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infox = df_texts_recueil[df_texts_recueil['infox']==1.0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d78270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infox = df_infox.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58eac7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_afp =  pd.read_csv('data/tmp/221118-TextsAfp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b3875f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>infox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.francesoir.fr/politique-monde/pres...</td>\n",
       "      <td>Présidentielle au Brésil: Bolsonaro talonne Lu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.francesoir.fr/politique-france/la-...</td>\n",
       "      <td>La France lance un plan de sobriété énergétiqu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.francesoir.fr/politique-monde/mani...</td>\n",
       "      <td>Manifestations des femmes en Iran contre le po...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.francesoir.fr/politique-france/aff...</td>\n",
       "      <td>Affaire Quatennens: LFI sous la pression de la...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.francesoir.fr/politique-monde/covi...</td>\n",
       "      <td>Covid-19: pour Joe Biden, \"la pandémie est ter...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>https://www.francesoir.fr/lifestyle-gastronomi...</td>\n",
       "      <td>La deuxième vie des coquilles d'huîtres\\nLes h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>https://www.francesoir.fr/lifestyle-gastronomi...</td>\n",
       "      <td>La truffe se fait rare\\nVictime du réchauffeme...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>https://www.francesoir.fr/lifestyle-gastronomi...</td>\n",
       "      <td>Rungis prépare un Noël opulent malgré les atte...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>https://www.francesoir.fr/lifestyle-gastronomi...</td>\n",
       "      <td>Gastronomie: le Franco-Suisse Benoît Violier m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>https://www.francesoir.fr/lifestyle-gastronomi...</td>\n",
       "      <td>Paris: le \"doggy bag\" désormais proposé dans 1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3237 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0     https://www.francesoir.fr/politique-monde/pres...   \n",
       "1     https://www.francesoir.fr/politique-france/la-...   \n",
       "2     https://www.francesoir.fr/politique-monde/mani...   \n",
       "3     https://www.francesoir.fr/politique-france/aff...   \n",
       "4     https://www.francesoir.fr/politique-monde/covi...   \n",
       "...                                                 ...   \n",
       "3232  https://www.francesoir.fr/lifestyle-gastronomi...   \n",
       "3233  https://www.francesoir.fr/lifestyle-gastronomi...   \n",
       "3234  https://www.francesoir.fr/lifestyle-gastronomi...   \n",
       "3235  https://www.francesoir.fr/lifestyle-gastronomi...   \n",
       "3236  https://www.francesoir.fr/lifestyle-gastronomi...   \n",
       "\n",
       "                                                   text  infox  \n",
       "0     Présidentielle au Brésil: Bolsonaro talonne Lu...    0.0  \n",
       "1     La France lance un plan de sobriété énergétiqu...    0.0  \n",
       "2     Manifestations des femmes en Iran contre le po...    0.0  \n",
       "3     Affaire Quatennens: LFI sous la pression de la...    0.0  \n",
       "4     Covid-19: pour Joe Biden, \"la pandémie est ter...    0.0  \n",
       "...                                                 ...    ...  \n",
       "3232  La deuxième vie des coquilles d'huîtres\\nLes h...    0.0  \n",
       "3233  La truffe se fait rare\\nVictime du réchauffeme...    0.0  \n",
       "3234  Rungis prépare un Noël opulent malgré les atte...    0.0  \n",
       "3235  Gastronomie: le Franco-Suisse Benoît Violier m...    0.0  \n",
       "3236  Paris: le \"doggy bag\" désormais proposé dans 1...    0.0  \n",
       "\n",
       "[3237 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts_afp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89c81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.read_csv('data/prod/221125-InfoxWords.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08f10d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count</th>\n",
       "      <th>rare_1</th>\n",
       "      <th>rare_2</th>\n",
       "      <th>rare_3</th>\n",
       "      <th>rare_4</th>\n",
       "      <th>rare_5</th>\n",
       "      <th>rare_6</th>\n",
       "      <th>rare_7</th>\n",
       "      <th>common_50</th>\n",
       "      <th>common_80</th>\n",
       "      <th>common_120</th>\n",
       "      <th>common_200</th>\n",
       "      <th>common_500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>114412</td>\n",
       "      <td>23980</td>\n",
       "      <td>138392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>63402</td>\n",
       "      <td>12901</td>\n",
       "      <td>76303</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>49361</td>\n",
       "      <td>9921</td>\n",
       "      <td>59282</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>38704</td>\n",
       "      <td>10142</td>\n",
       "      <td>48846</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>les</th>\n",
       "      <td>38053</td>\n",
       "      <td>10363</td>\n",
       "      <td>48416</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mayr</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mazari</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maçonnique</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maïté</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>þórólfur</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54209 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            count_0  count_1   count  rare_1  rare_2  rare_3  rare_4  rare_5  \\\n",
       "de           114412    23980  138392   False   False   False   False   False   \n",
       "la            63402    12901   76303   False   False   False   False   False   \n",
       "le            49361     9921   59282   False   False   False   False   False   \n",
       "et            38704    10142   48846   False   False   False   False   False   \n",
       "les           38053    10363   48416   False   False   False   False   False   \n",
       "...             ...      ...     ...     ...     ...     ...     ...     ...   \n",
       "mayr              0        1       1    True    True    True    True    True   \n",
       "mazari            0        1       1    True    True    True    True    True   \n",
       "maçonnique        0        2       2   False    True    True    True    True   \n",
       "maïté             0        1       1    True    True    True    True    True   \n",
       "þórólfur          0        1       1    True    True    True    True    True   \n",
       "\n",
       "            rare_6  rare_7  common_50  common_80  common_120  common_200  \\\n",
       "de           False   False       True       True        True        True   \n",
       "la           False   False       True       True        True        True   \n",
       "le           False   False       True       True        True        True   \n",
       "et           False   False       True       True        True        True   \n",
       "les          False   False       True       True        True        True   \n",
       "...            ...     ...        ...        ...         ...         ...   \n",
       "mayr          True    True      False      False       False       False   \n",
       "mazari        True    True      False      False       False       False   \n",
       "maçonnique    True    True      False      False       False       False   \n",
       "maïté         True    True      False      False       False       False   \n",
       "þórólfur      True    True      False      False       False       False   \n",
       "\n",
       "            common_500  \n",
       "de                True  \n",
       "la                True  \n",
       "le                True  \n",
       "et                True  \n",
       "les               True  \n",
       "...                ...  \n",
       "mayr             False  \n",
       "mazari           False  \n",
       "maçonnique       False  \n",
       "maïté            False  \n",
       "þórólfur         False  \n",
       "\n",
       "[54209 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83874cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_words_small = list(df_words[df_words['common_80']].index)+list(df_words[df_words['rare_1']].index)\n",
    "ignore_words_medium = list(df_words[df_words['common_80']].index)+list(df_words[df_words['rare_2']].index)\n",
    "ignore_words_large = list(df_words[df_words['common_200']].index)+list(df_words[df_words['rare_5']].index)\n",
    "ignore_words_xlarge = list(df_words[df_words['common_500']].index)+list(df_words[df_words['rare_7']].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32351c1",
   "metadata": {},
   "source": [
    "# Experience\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c48ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8a49193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load(\"fr_core_news_sm\")\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "#nlp = spacy.load(\"fr_dep_news_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fed9afe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b17647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Un président doit savoir prendre ses responsabilités\" - Lettre d'un médecin à E. Macron\n",
      "LETTRE OUVERTE - Monsieur le Président,Je vais me faire vacciner contre le COVID. Cet acte médical se déroulera, de fait, en plein Été. Il a pour objectif de nous protéger, mes patients et moi, d’un coronavirus à ARN, extrêmement instable, à contaminations manu-portée et aérienne, et à variation saisonnière manifeste sous nos latitudes.En tant que médecin, l’ordre m’en est donc intimé. Dont act. Il n’est pas question pour moi de contrevenir à une injonction émanant du pouvoir politique de mon pays, formulée avec la bénédiction de mon autorité ordinale, et sur recommandations de l’Académie Nationale de Médecine. Encore moins question de produire de faux certificats, même si cette éventualité m’a été soufflée par de respectables confrères. Eux, ne manifestent ouvertement aucune opposition à cette campagne vaccinale, à laquelle ils se sont pourtant discrètement ainsi soustraits. Leur étrange mutisme traduit la peur qu’ils semblent nourrir : être mis au ban de leur corporation, voire, être poursuivis par les instances disciplinaires du Conseil National de l’Ordre des Médecins. Comment leur en vouloir ?Si vous me connaissiez, vous seriez étonné. Je suis un vaccinolâtre de la première heure. Mon carnet de santé, et ceux de mes enfants, pourront en attester. Je me fais vacciner tous les ans contre la grippe saisonnière, suivant la recommandation de nos autorités de Santé. Je suis psychiatre/addictologue, comportementaliste. Adepte du raisonnement scientifique et de l’Evidence Based Medicine. La vraie : celle qui fonde notre pratique depuis son origine. Pas de son interprétation actuelle, dénaturée, scandée par des méthodologistes intégristes. Sous couvert de rigueur, ils omettent de prendre en considération la complexité et la singularité de notre physiologie humaine. Ils ont oublié que la médecine ne peut se suffire de protocoles standardisés et généraux, servis par des algorithmes hasardeux et réducteurs. Le temps de l’expérience est indispensable à la connaissance médicale. Ce temps n’est pas le même que le temps politiques et médiatiques, certes. J’exerce à Bordeaux, capitale d’un Sud-Ouest relativement épargné par la pandémie. Les données épidémiologiques à la portée de tous en attestent. La cour des comptes a rapporté une activité des services de réanimation du CHU de Bordeaux, lors du premier confinement, inférieure aux mêmes périodes pour les années 2019 et 2018. Les interruptions de suivis et les reports d’interventions ont généré de grandes difficultés dans les mois qui suivirent ces mesures « préventives ». Mon cabinet est resté ouvert. Mes patients, suivis. Les précautions sanitaires appliquées.Par respect des lois de mon pays, je vais me faire vacciner. Permettez-moi néanmoins, Monsieur le Président, d’exercer ma liberté d’expression et d’opinion, puisqu’il m’en est encore donné le droit. Ma qualité de médecin ne m’en prive pas, à ma connaissance. Les propos qui vont suivre se basent sur des données scientifiques dont je tiens les sources à votre entière disposition. J’accepte l’injection vaccinale sans pouvoir en valider la balance bénéfice/risque, ni pour moi, ni même pour la grande majorité de mes concitoyens. Ce traitement doit me protéger d’un virus dont la létalité est évaluée, pour ma classe d’âge, à 0,05 %. La létalité supposée de l’actuel variant Delta va peut-être se confirmer comme bien moindre. Cette inoculation va être effectuée en été, alors que les données épidémiologiques montrent une quasi-disparition des hospitalisations et des décès pour COVID en Europe. L’éventuelle immunité (transitoire) acquise ne peut en aucun cas être assurée sur les résurgences épidémiques à venir (automnales ou printanières). On ne peut déterminer quel sera le profil génomique des agents infectieux à venir. Vous m’imposez l’inoculation d’un produit pharmaceutique qui ne dispose que d’une AMM conditionnelle, transitoire, en attente des données manquantes (nécessaires pour en valider le caractère total et permanent). Cet acte vaccinal m’est dicté par mon ministre de tutelle, dont je découvre avec stupéfaction qu’il ignorait manifestement ce cadre de commercialisation bien particulier.En conséquence, devant l’incertitude portant sur les futures variations génomiques du SARS-Cov2, sur le contexte saisonnier actuel et sur le caractère conditionnel de l’AMM, vous m’accorderez, Monsieur le Président, qu’il est impossible d’évaluer une quelconque balance bénéfice/risque à l’acte médical que vous m’imposez aujourd’hui. Un président doit savoir prendre ses responsabilités. Soyez assuré que nous retiendrons la vôtre, dans le cas présent. Ne vous méprenez pas, cette vaccination ne m’effraie pas outre mesure, à titre personnel. Je ne crains pas qu’une puce 5G me soit inoculée. Je ne pense pas me transformer en cyborg postvaccination. Je n’ai jamais été de nature inquiète vis-à-vis de nos médicaments. Ce n’est ni la première fois, ni la dernière, que j’administrerai à mon organisme un traitement à la balance bénéfice/inconvénient douteuse, ou en passe d’être reconsidérée. En revanche, le contexte dans lequel cela va s’effectuer est sans précédent.Ainsi, j’espère que vous comprendrez qu’il est pour moi hors de question de signer un quelconque « consentement éclairé » pour accompagner cette injection. Il m’aurait été impossible d’ailleurs d’effectuer un tel recueil auprès de patients à qui je n’aurais pu délivrer des informations fiables et accessibles concernant ledit produit. Merci de prendre en considération que je vous demande d’assumer pleinement vos responsabilités vis-à-vis des conséquences éventuelles de cette injection. Ces spécialités pharmacologiques ont obtenu une AMM conditionnelle alors que des données scientifiques plaidaient pour un recours raisonnable à des traitements précoces dont l’innocuité était largement éprouvée. Je vais me faire vacciner pour un agent infectieux peu létal pour moi. Plus précisément, pour les récents variants du SARS-Cov2 et ceux à venir. Impossible de prédire l’efficacité du procédé vaccinal actuel vis-à-vis d’eux. J’ai bien entendu l’argument de la vaccination altruiste, mais j’attends toujours des données fiables et exploitables démontrant la baisse de la contagiosité des vaccinés pour les mutants viraux actuels. L’exemple israélien permet de douter. Je me fais vacciner par une technologie impliquant des modes d’actions expérimentaux alors que le vaccin à protéines recombinantes de SANOFI et le vaccin à virus complet inactivé de VALNEVA devraient être accessibles cet automne.J’assume, Monsieur le Président, la teneur de mes propos, en dépit du climat de terreur et l’inquiétante vindicte qui sévit sur les réseaux sociaux. Je prends la parole malgré les procédures judiciaires qui poursuivent d’ores et déjà certains de mes confrères. J’estime de mon devoir de médecin d’exprimer un avis professionnel sur la situation sanitaire à laquelle sont confrontés mes concitoyens. Je pense respecter les règles déontologiques de ma profession et les lois de mon pays. Je me comporte donc comme un médecin et un citoyen, somme toute, discipliné. Je profite cependant de ce courrier pour vous faire part, Monsieur le Président, des limites de ma docilité. La santé et l’intérêt de mes enfants me seront toujours prioritaires à toute autre considération.S’il vous venait à l’esprit d’imposer cette vaccination aux mineurs, je ne pourrai l’accepter. Nos enfants ont été moins impactés par le virus que par les restrictions sanitaires qui leur ont été imposées. Il serait inacceptable que d’autres décisions, contraires à leur intérêt, soient encore prises.Je vous remercie de votre attention. Vous avez compris l’importance que ce courrier représentait pour le médecin, le citoyen, mais surtout le père que je suis.Veuillez agréer, Monsieur le Président, mes respectueuses salutations.\n"
     ]
    }
   ],
   "source": [
    "text = df_infox['text'][1]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f544606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>pos_</th>\n",
       "      <th>tag_</th>\n",
       "      <th>dep_</th>\n",
       "      <th>shape_</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>\"</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un</td>\n",
       "      <td>un</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>Xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>président</td>\n",
       "      <td>président</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doit</td>\n",
       "      <td>devoir</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>savoir</td>\n",
       "      <td>savoir</td>\n",
       "      <td>AUX</td>\n",
       "      <td>AUX</td>\n",
       "      <td>dep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>mes</td>\n",
       "      <td>mon</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>respectueuses</td>\n",
       "      <td>respectueux</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>salutations</td>\n",
       "      <td>salutation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1434 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               text       lemma_   pos_   tag_   dep_ shape_  is_alpha  \\\n",
       "0                 \"            \"  PUNCT  PUNCT  punct      \"     False   \n",
       "1                Un           un    DET    DET    det     Xx      True   \n",
       "2         président    président   NOUN   NOUN  nsubj   xxxx      True   \n",
       "3              doit       devoir   VERB   VERB   ROOT   xxxx      True   \n",
       "4            savoir       savoir    AUX    AUX    dep   xxxx      True   \n",
       "...             ...          ...    ...    ...    ...    ...       ...   \n",
       "1429              ,            ,  PUNCT  PUNCT  punct      ,     False   \n",
       "1430            mes          mon    DET    DET    det    xxx      True   \n",
       "1431  respectueuses  respectueux    ADJ    ADJ   amod   xxxx      True   \n",
       "1432    salutations   salutation   NOUN   NOUN    obj   xxxx      True   \n",
       "1433              .            .  PUNCT  PUNCT  punct      .     False   \n",
       "\n",
       "      is_stop  \n",
       "0       False  \n",
       "1        True  \n",
       "2       False  \n",
       "3        True  \n",
       "4       False  \n",
       "...       ...  \n",
       "1429    False  \n",
       "1430     True  \n",
       "1431    False  \n",
       "1432    False  \n",
       "1433    False  \n",
       "\n",
       "[1434 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "tokens = []\n",
    "for token in doc:\n",
    "    item = {}\n",
    "    item['text'] = token.text\n",
    "    item['lemma_'] = token.lemma_\n",
    "    item['pos_'] = token.pos_\n",
    "    item['tag_'] = token.tag_\n",
    "    item['dep_'] = token.dep_\n",
    "    item['shape_'] = token.shape_\n",
    "    item['is_alpha'] = token.is_alpha\n",
    "    item['is_stop'] = token.is_stop\n",
    "    tokens.append(item)\n",
    "df_token = pd.DataFrame(tokens)\n",
    "df_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d92fe2",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "659616c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ents(text):\n",
    "    ents = {}\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        ents[ent.text] = ent.label_\n",
    "#        print(ent.text)\n",
    "    return ents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94c53765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E. Macron\\nLETTRE': 'PER',\n",
       " 'Académie Nationale': 'ORG',\n",
       " 'Conseil National de l’Ordre des Médecins': 'ORG',\n",
       " 'Santé.': 'MISC',\n",
       " 'Bordeaux': 'LOC',\n",
       " 'Sud-Ouest': 'LOC',\n",
       " 'Monsieur le Président': 'PER',\n",
       " 'Delta': 'LOC',\n",
       " 'COVID': 'MISC',\n",
       " 'Europe': 'LOC',\n",
       " 'Cov2': 'LOC',\n",
       " 'SANOFI': 'ORG',\n",
       " 'VALNEVA': 'LOC'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ents(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692002bb",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d845f",
   "metadata": {},
   "source": [
    "### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6efc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.text\n",
    "\n",
    "importlib.reload(patat.util.text)\n",
    "preprocessor = patat.util.text.preprocess\n",
    "#preprocessor=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b5cbb",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52367d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patat.ml.lex_analyser import LexAnalyser\n",
    "\n",
    "lex = LexAnalyser()\n",
    "\n",
    "tokenizer = lex.get_lemmas_from_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fb32f",
   "metadata": {},
   "source": [
    "### TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28886029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#afp_size = 3000\n",
    "#afp_size = 120\n",
    "#afp_size = 50\n",
    "afp_size = 20\n",
    "#afp_size = 0\n",
    "df_ml = pd.concat([df_texts_recueil,df_texts_afp.sample(afp_size,random_state=random_state)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd88a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#stop_words = ignore_words_small\n",
    "#stop_words = ignore_words_medium\n",
    "stop_words = ignore_words_large\n",
    "#stop_words = ignore_words_xlarge\n",
    "vectorizer = TfidfVectorizer(lowercase=True, preprocessor=preprocessor, tokenizer=tokenizer, stop_words=stop_words)\n",
    "#vectorizer = CountVectorizer(lowercase=True, preprocessor=preprocessor, tokenizer=tokenizer, stop_words=stop_words)\n",
    "count_matrix = vectorizer.fit_transform(df_ml['text'])\n",
    "count_array = count_matrix.toarray()\n",
    "df_tf = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
    "df_tf.shape\n",
    "\n",
    "df_X = df_tf\n",
    "X = df_X\n",
    "\n",
    "len(df_X.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac01c5",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b371d9e2",
   "metadata": {},
   "source": [
    "### Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de04b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e295bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df_X\n",
    "y=df_ml['infox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=random_state,train_size=train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742f032",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f186b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = {\n",
    "    \"Logistic Regression\" : LogisticRegression(C=1000, random_state=random_state, solver='lbfgs', multi_class='ovr', max_iter=1000),\n",
    "    \"Neural Network\" : MLPClassifier(alpha=1, max_iter=1000, hidden_layer_sizes=(8,8), random_state=random_state),\n",
    "    \"RBF SVM\" : SVC(gamma=2, C=1, probability=True, random_state=random_state),\n",
    "    \"Gaussian Naive Bayes\" : GaussianNB(),\n",
    "    \"Multinomial Naive Bayes\" : MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None),\n",
    "#    \"Nearest Neighbors\" : KNeighborsClassifier(3),\n",
    "    \"Linear SVM\" : SVC(kernel=\"linear\", C=0.025, probability=True, random_state=random_state),\n",
    "    \"Gaussian Process\" : GaussianProcessClassifier(1.0 * RBF(1.0), random_state=random_state),\n",
    "    \"Decision Tree\" : DecisionTreeClassifier(max_depth=5, random_state=random_state),\n",
    "    \"Random Forest\" : RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, random_state=random_state),\n",
    "    \"AdaBoost\" : AdaBoostClassifier(random_state=random_state),\n",
    "    \"QDA\" : QuadraticDiscriminantAnalysis(),\n",
    "    'Gradient Boosting': HistGradientBoostingClassifier(random_state=random_state),\n",
    "    'Dummy' : DummyClassifier(strategy='uniform', random_state=random_state),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710842c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=random_state,train_size=0.75)\n",
    "y_preds = {}\n",
    "y_probas = {}\n",
    "fit_times = {}\n",
    "proba_times = {}\n",
    "\n",
    "#for name, classifier in zip(names, classifiers):\n",
    "for name in predictors.keys():\n",
    "    \n",
    "    classifier = predictors[name]\n",
    "    print(f'Training {name}')\n",
    "    \n",
    "    start = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    stop = time.time()\n",
    "    fit_times[name] = stop - start\n",
    "    \n",
    "    print(f'Training time : {fit_times[name]} s')\n",
    "    \n",
    "    y_preds[name] = classifier.predict(X_test)\n",
    "    \n",
    "    start = time.time()\n",
    "    y_probas[name] = classifier.predict_proba(X_test)\n",
    "    stop = time.time()\n",
    "    proba_times[name] = stop - start\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26254ebf",
   "metadata": {},
   "source": [
    "## Mesure Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676aa70",
   "metadata": {},
   "source": [
    "### ROC et AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0).clf()\n",
    "for name in y_probas.keys():\n",
    "    y_proba = y_probas[name][:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba)\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 4)\n",
    "    plt.plot(fpr,tpr,label=f\"{name}, AUC={auc}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_results = {}\n",
    "for key in y_preds.keys():\n",
    "    bench_results[key] = {}\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_proba)\n",
    "    bench_results[key]['roc_auc'] = metrics.roc_auc_score(y_test, y_probas[key][:, 1])\n",
    "    bench_results[key]['accuracy']=metrics.accuracy_score(y_test, y_preds[key])\n",
    "    bench_results[key]['recall']=metrics.recall_score(y_test, y_preds[key])\n",
    "    bench_results[key]['f1']=metrics.f1_score(y_test, y_preds[key])\n",
    "    bench_results[key]['log_loss'] = metrics.log_loss(y_test, y_preds[key])\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_preds[key],normalize='all')\n",
    "    bench_results[key]['false_positive']=cnf_matrix[0,1]\n",
    "    bench_results[key]['false_negative']=cnf_matrix[1,0]\n",
    "    bench_results[key]['fit_time']=fit_times[key]\n",
    "    bench_results[key]['proba_time']=proba_times[key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6189694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench = pd.DataFrame(bench_results).T\n",
    "df_bench = df_bench.sort_values('roc_auc',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a48f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train size \\t{len(y_train)} = {int(len(y_train)-y_train.sum())} False + {int(y_train.sum())} True' )\n",
    "print(f'Test size \\t{len(y_test)} = {int(len(y_test)-y_test.sum())} False + {int(y_test.sum())} True\\n' )\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df_bench,y='accuracy',x='roc_auc',hue=df_bench.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76996d3a",
   "metadata": {},
   "source": [
    "# Sauvegarde des résultats\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7949bc",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "---\n",
    "- Framework pour comparer les algorithmes : OK\n",
    "- Résultats encourageants pour les prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06b261",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360655",
   "metadata": {},
   "source": [
    "# Bricolages\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
