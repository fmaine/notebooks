{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9f99fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3ec4689",
   "metadata": {},
   "source": [
    "# Plateforme Agnostique de Traitement et d'Analyse des Textes\n",
    "### Carnet d'expérimentation\n",
    "---\n",
    "\n",
    "## Sujet : Camembert Embeddings\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601e626",
   "metadata": {},
   "source": [
    "# Observations et environnement\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0f3b8",
   "metadata": {},
   "source": [
    "## Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525fef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rs = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0de4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Geek/Work/Patat\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32256b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b7201",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94420655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.file\n",
    "\n",
    "filename = 'data/prod/230517-OIDS-Label.pickle'\n",
    "\n",
    "df_label = patat.util.file.pickle_load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5245cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['infox', 'entites_nommees', 'ouverture_esprit', 'faits', 'opinions',\n",
    "       'propos_raportes', 'sources_citees', 'fausse_nouvelle', 'insinuations',\n",
    "       'exageration', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07012a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infox</th>\n",
       "      <th>entites_nommees</th>\n",
       "      <th>ouverture_esprit</th>\n",
       "      <th>faits</th>\n",
       "      <th>opinions</th>\n",
       "      <th>propos_raportes</th>\n",
       "      <th>sources_citees</th>\n",
       "      <th>fausse_nouvelle</th>\n",
       "      <th>insinuations</th>\n",
       "      <th>exageration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>552.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.618159</td>\n",
       "      <td>0.063512</td>\n",
       "      <td>0.717662</td>\n",
       "      <td>0.547264</td>\n",
       "      <td>0.244085</td>\n",
       "      <td>0.400996</td>\n",
       "      <td>0.152120</td>\n",
       "      <td>0.331671</td>\n",
       "      <td>0.317029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.486140</td>\n",
       "      <td>0.244033</td>\n",
       "      <td>0.450417</td>\n",
       "      <td>0.498071</td>\n",
       "      <td>0.429811</td>\n",
       "      <td>0.490406</td>\n",
       "      <td>0.359361</td>\n",
       "      <td>0.471107</td>\n",
       "      <td>0.465741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            infox  entites_nommees  ouverture_esprit       faits    opinions  \\\n",
       "count  900.000000       804.000000        803.000000  804.000000  804.000000   \n",
       "mean     0.414444         0.618159          0.063512    0.717662    0.547264   \n",
       "std      0.492900         0.486140          0.244033    0.450417    0.498071   \n",
       "min      0.000000         0.000000          0.000000    0.000000    0.000000   \n",
       "25%      0.000000         0.000000          0.000000    0.000000    0.000000   \n",
       "50%      0.000000         1.000000          0.000000    1.000000    1.000000   \n",
       "75%      1.000000         1.000000          0.000000    1.000000    1.000000   \n",
       "max      1.000000         1.000000          1.000000    1.000000    1.000000   \n",
       "\n",
       "       propos_raportes  sources_citees  fausse_nouvelle  insinuations  \\\n",
       "count       803.000000      803.000000       802.000000    802.000000   \n",
       "mean          0.244085        0.400996         0.152120      0.331671   \n",
       "std           0.429811        0.490406         0.359361      0.471107   \n",
       "min           0.000000        0.000000         0.000000      0.000000   \n",
       "25%           0.000000        0.000000         0.000000      0.000000   \n",
       "50%           0.000000        0.000000         0.000000      0.000000   \n",
       "75%           0.000000        1.000000         0.000000      1.000000   \n",
       "max           1.000000        1.000000         1.000000      1.000000   \n",
       "\n",
       "       exageration  \n",
       "count   552.000000  \n",
       "mean      0.317029  \n",
       "std       0.465741  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label[labels].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fbc2c",
   "metadata": {},
   "source": [
    "### Urls duppliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd771182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.duplicated(subset='url').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff2696",
   "metadata": {},
   "source": [
    "### Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1d4b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site\n",
       "www.francesoir.fr                    169\n",
       "www.francetvinfo.fr                   91\n",
       "www.breizh-info.com                   66\n",
       "www.wikistrike.com                    62\n",
       "lezarceleurs.blogspot.com             58\n",
       "lesmoutonsrebelles.com                47\n",
       "lemediaen442.fr                       32\n",
       "www.profession-gendarme.com           28\n",
       "lesdeqodeurs.fr                       28\n",
       "fr.sott.net                           26\n",
       "www.dreuz.info                        25\n",
       "www.lelibrepenseur.org                23\n",
       "www.polemia.com                       19\n",
       "reseauinternational.net               17\n",
       "actu.fr                               17\n",
       "www.mondialisation.ca                 16\n",
       "www.nouvelordremondial.cc             14\n",
       "lesakerfrancophone.fr                 13\n",
       "www.lesalonbeige.fr                   13\n",
       "www.voltairenet.org                   12\n",
       "lesobservateurs.ch                     9\n",
       "www.anguillesousroche.com              9\n",
       "lecourrier-du-soir.com                 9\n",
       "www.cnews.fr                           9\n",
       "www.preuvesduparanormal.fr             8\n",
       "www.les-crises.fr                      8\n",
       "infodujour.fr                          8\n",
       "www.medias-presse.info                 7\n",
       "fr.novopress.info                      7\n",
       "www.alnas.fr                           7\n",
       "www.bvoltaire.fr                       6\n",
       "ripostelaique.com                      5\n",
       "lalettrepatriote.com                   4\n",
       "theconversation.com                    4\n",
       "lumieresurgaia.com                     4\n",
       "francais.rt.com                        3\n",
       "www.la-petite-souris-normande.com      3\n",
       "www.revue-elements.com                 3\n",
       "www.epochtimes.fr                      2\n",
       "bonsens.info                           2\n",
       "lecourrierdesstrateges.fr              2\n",
       "qactus.fr                              2\n",
       "extime.fr                              2\n",
       "elucid.media                           2\n",
       "www.fdesouche.com                      2\n",
       "planetes360.fr                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.value_counts('site')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b548bc6",
   "metadata": {},
   "source": [
    "# Experience\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f770fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f708741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Camembert version\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "model_name = 'camembert-base'\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "model = CamembertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b6a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(sentence,tokenizer,model):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    max_length = 512  # Taille maximale de la phrase d'entrée\n",
    "    input_ids = input_ids[:max_length]\n",
    "    input_ids = input_ids + [0] * (max_length - len(input_ids))  # Padding\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0)  # Ajoute une dimension de lot\n",
    "    attention_mask = torch.tensor(attention_mask).unsqueeze(0)  # Ajoute une dimension de lot\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    embeddings = outputs[0]  # Récupère les embeddings de la dernière couche cachée\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c32e1457",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Ceci est un test avec une phrase un peu plus longue. On verra ce que ca donne...'\n",
    "outputs = get_outputs(sentence,tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3056a47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5668a895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0051,  0.0997,  0.1328,  ..., -0.0749, -0.0180, -0.0609],\n",
       "         [-0.0768,  0.1755,  0.1299,  ..., -0.0244, -0.0549, -0.1113],\n",
       "         [ 0.0987,  0.0403, -0.2107,  ..., -0.0356,  0.1181, -0.3143],\n",
       "         ...,\n",
       "         [-0.0051,  0.0997,  0.1328,  ..., -0.0749, -0.0180, -0.0609],\n",
       "         [-0.0051,  0.0997,  0.1328,  ..., -0.0749, -0.0180, -0.0609],\n",
       "         [-0.0832,  0.0825,  0.1666,  ..., -0.0583, -0.0570,  0.0176]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67f8e633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 NativeLayerNormBackward0                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'NativeLayerNormBackward0'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 NativeLayerNormBackward0                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'NativeLayerNormBackward0'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NativeLayerNormBackward0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf586b92",
   "metadata": {},
   "source": [
    "## Calcul des embeddings des textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd02103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717298aee8b34968b9179a0362c1cd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/904 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_label['embeddings']=df_label['text'].progress_apply(lambda text: get_embeddings(text,tokenizer,model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d7442",
   "metadata": {},
   "source": [
    "## Prédiction infox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d87b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf87a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_df_ml(label,df_label):\n",
    "    df_0 = df_label[df_label[label] == 0]\n",
    "    df_1 = df_label[df_label[label] == 1]\n",
    "    min_sample = min(len(df_0),len(df_1))\n",
    "    df_0=df_0.sample(min_sample,random_state=_rs)\n",
    "    df_1=df_1.sample(min_sample,random_state=_rs)\n",
    "    df_ml = pd.concat([df_0,df_1])\n",
    "    df_ml = df_ml.sample(frac=1,random_state=_rs)\n",
    "    return df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11178211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = get_balanced_df_ml('infox',df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2827113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6dca47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([r['embeddings'] for i,r in df_ml.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd587e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bedc7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ml['infox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a28c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=_rs, solver='lbfgs', multi_class='ovr', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26ec979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(logreg, X, y, cv=4,scoring=('roc_auc','f1','accuracy','precision','recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4e59892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time          0.044024\n",
       "score_time        0.008357\n",
       "test_roc_auc      0.838486\n",
       "test_f1           0.748893\n",
       "test_accuracy     0.760106\n",
       "test_precision    0.784991\n",
       "test_recall       0.718628\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c9861",
   "metadata": {},
   "source": [
    "## Prédiction liste de labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e17d8f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['infox', 'entites_nommees', 'ouverture_esprit', 'faits', 'opinions',\n",
    "       'propos_raportes', 'sources_citees', 'fausse_nouvelle', 'insinuations',\n",
    "       'exageration', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5a72be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_ml(label,df_label):\n",
    "    return df_label[df_label[label].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef6bbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_df_ml(label,df_label):\n",
    "    df_0 = df_label[df_label[label] == 0]\n",
    "    df_1 = df_label[df_label[label] == 1]\n",
    "    min_sample = min(len(df_0),len(df_1))\n",
    "    df_0=df_0.sample(min_sample,random_state=_rs)\n",
    "    df_1=df_1.sample(min_sample,random_state=_rs)\n",
    "    df_ml = pd.concat([df_0,df_1])\n",
    "    df_ml = df_ml.sample(frac=1,random_state=_rs)\n",
    "    return df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50f4da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(label,df_ml):\n",
    "    logreg = LogisticRegression(random_state=_rs, solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "    matrix = np.array([r['embeddings'] for i,r in df_ml.iterrows()])\n",
    "    X = pd.DataFrame(matrix)\n",
    "    y = df_ml[label]\n",
    "    classifier = logreg\n",
    "    scores = cross_validate(classifier, X, y, cv=4,scoring=('roc_auc','f1','accuracy','precision','recall'))\n",
    "    df_scores=pd.DataFrame(scores)\n",
    "    score_dic = df_scores.mean().to_dict()\n",
    "    score_dic['label']=label\n",
    "    score_dic['n_samples']=len(df_ml)\n",
    "    return score_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8192fe26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing infox\n",
      "Processing entites_nommees\n",
      "Processing ouverture_esprit\n",
      "Processing faits\n",
      "Processing opinions\n",
      "Processing propos_raportes\n",
      "Processing sources_citees\n",
      "Processing fausse_nouvelle\n",
      "Processing insinuations\n",
      "Processing exageration\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "for label in labels:\n",
    "    print(f'Processing {label}')\n",
    "    df_ml = get_balanced_df_ml(label,df_label)\n",
    "    score_list.append(get_scores(label,df_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f88c0f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>label</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041651</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.838486</td>\n",
       "      <td>0.748893</td>\n",
       "      <td>0.760106</td>\n",
       "      <td>0.784991</td>\n",
       "      <td>0.718628</td>\n",
       "      <td>infox</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027566</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.740149</td>\n",
       "      <td>0.681552</td>\n",
       "      <td>0.671028</td>\n",
       "      <td>0.662224</td>\n",
       "      <td>0.703435</td>\n",
       "      <td>entites_nommees</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012312</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>0.553008</td>\n",
       "      <td>0.461777</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.465659</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>ouverture_esprit</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028933</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.633944</td>\n",
       "      <td>0.603768</td>\n",
       "      <td>0.605807</td>\n",
       "      <td>0.603735</td>\n",
       "      <td>0.608631</td>\n",
       "      <td>faits</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033426</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.720475</td>\n",
       "      <td>0.677674</td>\n",
       "      <td>0.679945</td>\n",
       "      <td>0.680962</td>\n",
       "      <td>0.675824</td>\n",
       "      <td>opinions</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.024109</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.616097</td>\n",
       "      <td>0.564339</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.559631</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>propos_raportes</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.038597</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.625849</td>\n",
       "      <td>0.563011</td>\n",
       "      <td>0.585404</td>\n",
       "      <td>0.596192</td>\n",
       "      <td>0.534182</td>\n",
       "      <td>sources_citees</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018965</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.694220</td>\n",
       "      <td>0.665156</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.649601</td>\n",
       "      <td>0.687903</td>\n",
       "      <td>fausse_nouvelle</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025813</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.787992</td>\n",
       "      <td>0.690320</td>\n",
       "      <td>0.703008</td>\n",
       "      <td>0.722594</td>\n",
       "      <td>0.661635</td>\n",
       "      <td>insinuations</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.022115</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>0.739570</td>\n",
       "      <td>0.655099</td>\n",
       "      <td>0.654323</td>\n",
       "      <td>0.656791</td>\n",
       "      <td>0.657241</td>\n",
       "      <td>exageration</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_roc_auc   test_f1  test_accuracy  \\\n",
       "0  0.041651    0.007901      0.838486  0.748893       0.760106   \n",
       "1  0.027566    0.007594      0.740149  0.681552       0.671028   \n",
       "2  0.012312    0.007437      0.553008  0.461777       0.490000   \n",
       "3  0.028933    0.007489      0.633944  0.603768       0.605807   \n",
       "4  0.033426    0.007813      0.720475  0.677674       0.679945   \n",
       "5  0.024109    0.007415      0.616097  0.564339       0.561224   \n",
       "6  0.038597    0.008178      0.625849  0.563011       0.585404   \n",
       "7  0.018965    0.007454      0.694220  0.665156       0.655738   \n",
       "8  0.025813    0.007601      0.787992  0.690320       0.703008   \n",
       "9  0.022115    0.007457      0.739570  0.655099       0.654323   \n",
       "\n",
       "   test_precision  test_recall             label  n_samples  \n",
       "0        0.784991     0.718628             infox        746  \n",
       "1        0.662224     0.703435   entites_nommees        614  \n",
       "2        0.465659     0.471154  ouverture_esprit        102  \n",
       "3        0.603735     0.608631             faits        454  \n",
       "4        0.680962     0.675824          opinions        728  \n",
       "5        0.559631     0.576531   propos_raportes        392  \n",
       "6        0.596192     0.534182    sources_citees        644  \n",
       "7        0.649601     0.687903   fausse_nouvelle        244  \n",
       "8        0.722594     0.661635      insinuations        532  \n",
       "9        0.656791     0.657241       exageration        350  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76996d3a",
   "metadata": {},
   "source": [
    "# Sauvegarde des résultats\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd7c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f8729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7949bc",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360655",
   "metadata": {},
   "source": [
    "# Bricolages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9862890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.model.camembert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3262dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(patat.model.camembert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e0315",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = patat.model.camembert.Camembert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c0221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c182439",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2 = model.get_embeddings('Voici est un autre texte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d790a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([df_label['embeddings'][0],df_label['embeddings'][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1586e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
