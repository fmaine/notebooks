{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ec4689",
   "metadata": {},
   "source": [
    "# Plateforme Agnostique de Traitement et d'Analyse des Textes\n",
    "### Carnet d'expérimentation\n",
    "---\n",
    "\n",
    "## Sujet : Bert Embeddings\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601e626",
   "metadata": {},
   "source": [
    "# Observations et environnement\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0f3b8",
   "metadata": {},
   "source": [
    "## Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "525fef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rs = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d0de4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Geek\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32256b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b7201",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94420655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.file\n",
    "\n",
    "filename = 'data/prod/230517-OIDS-Label.pickle'\n",
    "\n",
    "df_label = patat.util.file.pickle_load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5245cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['infox', 'entites_nommees', 'ouverture_esprit', 'faits', 'opinions',\n",
    "       'propos_raportes', 'sources_citees', 'fausse_nouvelle', 'insinuations',\n",
    "       'exageration', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07012a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infox</th>\n",
       "      <th>entites_nommees</th>\n",
       "      <th>ouverture_esprit</th>\n",
       "      <th>faits</th>\n",
       "      <th>opinions</th>\n",
       "      <th>propos_raportes</th>\n",
       "      <th>sources_citees</th>\n",
       "      <th>fausse_nouvelle</th>\n",
       "      <th>insinuations</th>\n",
       "      <th>exageration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>552.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.618159</td>\n",
       "      <td>0.063512</td>\n",
       "      <td>0.717662</td>\n",
       "      <td>0.547264</td>\n",
       "      <td>0.244085</td>\n",
       "      <td>0.400996</td>\n",
       "      <td>0.152120</td>\n",
       "      <td>0.331671</td>\n",
       "      <td>0.317029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.486140</td>\n",
       "      <td>0.244033</td>\n",
       "      <td>0.450417</td>\n",
       "      <td>0.498071</td>\n",
       "      <td>0.429811</td>\n",
       "      <td>0.490406</td>\n",
       "      <td>0.359361</td>\n",
       "      <td>0.471107</td>\n",
       "      <td>0.465741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            infox  entites_nommees  ouverture_esprit       faits    opinions  \\\n",
       "count  900.000000       804.000000        803.000000  804.000000  804.000000   \n",
       "mean     0.414444         0.618159          0.063512    0.717662    0.547264   \n",
       "std      0.492900         0.486140          0.244033    0.450417    0.498071   \n",
       "min      0.000000         0.000000          0.000000    0.000000    0.000000   \n",
       "25%      0.000000         0.000000          0.000000    0.000000    0.000000   \n",
       "50%      0.000000         1.000000          0.000000    1.000000    1.000000   \n",
       "75%      1.000000         1.000000          0.000000    1.000000    1.000000   \n",
       "max      1.000000         1.000000          1.000000    1.000000    1.000000   \n",
       "\n",
       "       propos_raportes  sources_citees  fausse_nouvelle  insinuations  \\\n",
       "count       803.000000      803.000000       802.000000    802.000000   \n",
       "mean          0.244085        0.400996         0.152120      0.331671   \n",
       "std           0.429811        0.490406         0.359361      0.471107   \n",
       "min           0.000000        0.000000         0.000000      0.000000   \n",
       "25%           0.000000        0.000000         0.000000      0.000000   \n",
       "50%           0.000000        0.000000         0.000000      0.000000   \n",
       "75%           0.000000        1.000000         0.000000      1.000000   \n",
       "max           1.000000        1.000000         1.000000      1.000000   \n",
       "\n",
       "       exageration  \n",
       "count   552.000000  \n",
       "mean      0.317029  \n",
       "std       0.465741  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label[labels].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fbc2c",
   "metadata": {},
   "source": [
    "### Urls duppliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd771182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.duplicated(subset='url').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff2696",
   "metadata": {},
   "source": [
    "### Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1d4b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site\n",
       "www.francesoir.fr                    169\n",
       "www.francetvinfo.fr                   91\n",
       "www.breizh-info.com                   66\n",
       "www.wikistrike.com                    62\n",
       "lezarceleurs.blogspot.com             58\n",
       "lesmoutonsrebelles.com                47\n",
       "lemediaen442.fr                       32\n",
       "www.profession-gendarme.com           28\n",
       "lesdeqodeurs.fr                       28\n",
       "fr.sott.net                           26\n",
       "www.dreuz.info                        25\n",
       "www.lelibrepenseur.org                23\n",
       "www.polemia.com                       19\n",
       "reseauinternational.net               17\n",
       "actu.fr                               17\n",
       "www.mondialisation.ca                 16\n",
       "www.nouvelordremondial.cc             14\n",
       "lesakerfrancophone.fr                 13\n",
       "www.lesalonbeige.fr                   13\n",
       "www.voltairenet.org                   12\n",
       "lesobservateurs.ch                     9\n",
       "www.anguillesousroche.com              9\n",
       "lecourrier-du-soir.com                 9\n",
       "www.cnews.fr                           9\n",
       "www.preuvesduparanormal.fr             8\n",
       "www.les-crises.fr                      8\n",
       "infodujour.fr                          8\n",
       "www.medias-presse.info                 7\n",
       "fr.novopress.info                      7\n",
       "www.alnas.fr                           7\n",
       "www.bvoltaire.fr                       6\n",
       "ripostelaique.com                      5\n",
       "lalettrepatriote.com                   4\n",
       "theconversation.com                    4\n",
       "lumieresurgaia.com                     4\n",
       "francais.rt.com                        3\n",
       "www.la-petite-souris-normande.com      3\n",
       "www.revue-elements.com                 3\n",
       "www.epochtimes.fr                      2\n",
       "bonsens.info                           2\n",
       "lecourrierdesstrateges.fr              2\n",
       "qactus.fr                              2\n",
       "extime.fr                              2\n",
       "elucid.media                           2\n",
       "www.fdesouche.com                      2\n",
       "planetes360.fr                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.value_counts('site')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b548bc6",
   "metadata": {},
   "source": [
    "# Experience\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306ba37",
   "metadata": {},
   "source": [
    "## Get Bert Embeddings\n",
    "Choix n°0\n",
    "\n",
    "Pour obtenir un embedding de phrase avec BERT, vous pouvez suivre les étapes suivantes :\n",
    "\n",
    "1. Tout d'abord, assurez-vous d'avoir installé la bibliothèque Transformers de Hugging Face. Vous pouvez l'installer en utilisant la commande `pip install transformers`.\n",
    "\n",
    "2. Importez les bibliothèques nécessaires dans votre script :\n",
    "\n",
    "```python\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "```\n",
    "\n",
    "3. Chargez le modèle pré-entraîné de BERT et le tokenizer correspondant :\n",
    "\n",
    "```python\n",
    "model_name = 'bert-base-uncased'  # exemple pour BERT non-casé en anglais\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "```\n",
    "\n",
    "4. Convertissez votre phrase en tokens utilisables par BERT en utilisant le tokenizer :\n",
    "\n",
    "```python\n",
    "sentence = \"Votre phrase ici\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "```\n",
    "\n",
    "5. Convertissez les tokens en indices numériques que le modèle peut comprendre :\n",
    "\n",
    "```python\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "```\n",
    "\n",
    "6. Ajoutez des padding et des masques pour avoir une taille fixe d'entrée :\n",
    "\n",
    "```python\n",
    "max_length = 64  # Taille maximale de la phrase d'entrée\n",
    "input_ids = input_ids[:max_length]\n",
    "input_ids = input_ids + [0] * (max_length - len(input_ids))  # Padding\n",
    "attention_mask = [1] * len(input_ids)\n",
    "```\n",
    "\n",
    "7. Préparez les données en tant que tenseurs PyTorch :\n",
    "\n",
    "```python\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0)  # Ajoute une dimension de lot\n",
    "attention_mask = torch.tensor(attention_mask).unsqueeze(0)  # Ajoute une dimension de lot\n",
    "```\n",
    "\n",
    "8. Passez les données à travers le modèle BERT pour obtenir les embeddings :\n",
    "\n",
    "```python\n",
    "outputs = model(input_ids, attention_mask=attention_mask)\n",
    "embeddings = outputs[0]  # Récupère les embeddings de la dernière couche cachée\n",
    "```\n",
    "Les embeddings obtenus sont des tenseurs PyTorch qui représentent les vecteurs d'une taille de la phrase donnée.\n",
    "\n",
    "Notez que cette méthode utilise BERT base non-casé en anglais comme exemple, vous pouvez choisir un modèle différent en fonction de vos besoins linguistiques et de la casse des textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b3c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a0d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# English Bert version\n",
    "from transformers import BertTokenizer, BertModel\n",
    "model_name = 'bert-base-uncased'  # exemple pour BERT non-casé en anglais\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f708741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Camembert version\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "model_name = 'camembert-base'\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "model = CamembertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b6a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sentence,tokenizer,model):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    max_length = 512  # Taille maximale de la phrase d'entrée\n",
    "    input_ids = input_ids[:max_length]\n",
    "    input_ids = input_ids + [0] * (max_length - len(input_ids))  # Padding\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0)  # Ajoute une dimension de lot\n",
    "    attention_mask = torch.tensor(attention_mask).unsqueeze(0)  # Ajoute une dimension de lot\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    embeddings = outputs[0]  # Récupère les embeddings de la dernière couche cachée\n",
    "    return embeddings[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c32e1457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.06394589e-03,  9.97290388e-02,  1.32782057e-01, -1.41223207e-01,\n",
       "       -2.34577842e-02,  4.36505564e-02,  3.25186364e-03,  1.93185136e-01,\n",
       "        2.32618488e-02,  6.91335797e-02,  3.44001874e-02,  1.63361967e-01,\n",
       "       -7.94454068e-02,  9.57238898e-02,  2.68591940e-01,  2.20870338e-02,\n",
       "        6.40096068e-02, -8.44110250e-02,  1.07058696e-01, -1.41572759e-01,\n",
       "        3.04726381e-02, -7.29611069e-02, -3.19031179e-02, -3.52645546e-01,\n",
       "        2.42682531e-01, -2.10098833e-01, -4.53932956e-02, -1.08195864e-01,\n",
       "       -1.59330852e-02,  6.23205751e-02,  4.71787900e-02, -2.09260687e-01,\n",
       "        7.66488835e-02,  1.05318323e-01,  1.70413986e-01, -1.11778617e-01,\n",
       "       -5.83170131e-02,  1.07461050e-01, -1.19124502e-01, -4.59931567e-02,\n",
       "       -1.44121408e-01,  8.08116868e-02,  2.13408649e-01, -5.47286719e-02,\n",
       "        1.32382274e-01,  1.99937314e-01, -2.52126783e-01,  1.79821216e-02,\n",
       "       -7.60386288e-02,  9.41729546e-02,  5.94821572e-02,  1.07978750e-02,\n",
       "       -4.17250514e-01,  2.05845356e-01,  2.86676101e-02,  3.40586305e-02,\n",
       "       -6.82484955e-02, -9.93035138e-02,  7.42706954e-02,  1.61819868e-02,\n",
       "        8.11689049e-02,  1.09548815e-01,  6.63041770e-02, -8.25599208e-02,\n",
       "        2.59170588e-02,  1.03662880e-02, -9.22733322e-02,  1.36495426e-01,\n",
       "        8.85643885e-02, -1.84258103e-01,  5.90896644e-02,  2.02656075e-01,\n",
       "       -5.46416119e-02, -2.48712450e-02,  1.02461673e-01, -5.49824685e-02,\n",
       "       -3.33887301e-02,  8.35089758e-03, -3.53812277e-02,  5.30716926e-02,\n",
       "        3.53070349e-02, -1.92360744e-01, -1.02521196e-01, -3.19146886e-02,\n",
       "        6.69994671e-03,  1.98383063e-01, -1.00770220e-01, -3.72678414e-02,\n",
       "        1.39968529e-01, -5.94513193e-02,  2.36226082e-01, -9.68553871e-02,\n",
       "       -3.68217602e-02,  1.30987719e-01,  6.24394119e-02, -1.52396917e-01,\n",
       "        8.53157118e-02, -4.14486304e-02, -2.30219215e-02,  8.01205263e-02,\n",
       "       -1.79779017e+00, -1.63600385e-01, -1.46727413e-01,  1.13201603e-01,\n",
       "        1.31928101e-02, -2.41293646e-02, -1.14715621e-01, -1.16151586e-01,\n",
       "        1.06031829e-02, -9.40471739e-02, -2.09857374e-02,  5.79378195e-03,\n",
       "        7.13400543e-02, -1.75966695e-01,  2.17591107e-01,  1.38951063e-01,\n",
       "       -7.61912614e-02,  1.23242401e-01, -4.33872044e-02,  3.38141978e-01,\n",
       "       -2.69291867e-02,  1.52559392e-03, -8.14847797e-02, -5.88724799e-02,\n",
       "       -4.57642898e-02, -3.98550093e-01,  8.66260380e-02,  2.09418297e-01,\n",
       "       -1.60091117e-01, -2.40126904e-03,  3.00892025e-01, -1.72651127e-01,\n",
       "        7.97681957e-02,  1.92715123e-01, -8.82543772e-02,  4.24046069e-02,\n",
       "       -2.67820433e-04,  5.75866327e-02, -2.49519618e-03, -1.65819991e-02,\n",
       "        2.33996525e-01, -1.19860005e-02,  1.28235906e-01,  1.63553730e-02,\n",
       "       -2.25155383e-01,  2.14577794e-01,  3.38468105e-02, -7.55350441e-02,\n",
       "        1.61095038e-02,  9.01422054e-02, -2.44978592e-02,  1.42667200e-02,\n",
       "       -3.08976807e-02, -1.83021352e-01, -1.23114675e-01, -4.16520126e-02,\n",
       "       -1.35634514e-02,  3.00872445e-01,  2.95566171e-01, -7.07093924e-02,\n",
       "        1.80305652e-02, -2.35529155e-01,  1.14384070e-01,  3.91907878e-02,\n",
       "       -1.57326043e-01, -1.86389573e-02,  3.03648971e-02, -8.95896032e-02,\n",
       "       -1.00024439e-01,  1.40063867e-01, -3.01495045e-02, -1.20297775e-01,\n",
       "       -9.45662111e-02, -1.96658477e-01, -1.05095543e-02, -2.42668092e-02,\n",
       "        1.23309180e-01,  2.00107813e-01,  1.30058795e-01,  1.38641134e-01,\n",
       "        1.83567405e-02,  3.48273441e-02,  2.28588469e-03, -2.18526237e-02,\n",
       "        9.10803303e-02, -4.31027040e-02,  5.26859909e-02, -1.08542442e-01,\n",
       "        2.50553284e-02,  1.12500481e-01,  9.50577185e-02,  2.74567217e-01,\n",
       "       -1.04955323e-02, -4.10928205e-02, -9.18148160e-02,  8.42413679e-02,\n",
       "       -5.14076501e-02, -7.51812458e-02,  9.50539932e-02, -2.53207870e-02,\n",
       "       -5.69497515e-03, -1.67242251e-02, -2.76836404e-03, -1.08943768e-02,\n",
       "        9.84776095e-02,  1.20524809e-01, -3.58472429e-02, -7.55425692e-02,\n",
       "       -3.41518782e-02, -4.86929901e-03,  9.84089077e-02, -2.58804560e-02,\n",
       "        8.95613357e-02, -8.23704079e-02,  5.67022264e-02, -1.75779566e-01,\n",
       "        8.86022747e-02, -1.79030374e-01, -7.63340667e-02, -4.74313274e-02,\n",
       "        4.05360274e-02, -1.07319623e-01,  1.02126539e-01,  5.85972220e-02,\n",
       "        2.44396031e-02, -2.88273161e-03, -3.22165191e-02,  1.99578777e-01,\n",
       "       -1.32050171e-01, -1.45371193e-02,  2.64709651e-01, -6.01935238e-02,\n",
       "        1.66118234e-01,  9.30447429e-02,  1.07871227e-01, -7.17169791e-03,\n",
       "       -2.79412530e-02,  3.07630701e-03,  1.90329403e-01,  6.40073121e-02,\n",
       "       -7.71359503e-02, -1.25584736e-01,  1.00490972e-02,  2.48878598e-01,\n",
       "        1.59319043e-01, -9.17881355e-03,  8.93358663e-02, -1.29788429e-01,\n",
       "        3.68429236e-02,  2.12744951e-01, -5.29617369e-02, -8.07949528e-03,\n",
       "       -1.52912941e-02,  4.01540101e-02,  1.20932207e-01, -7.87013024e-02,\n",
       "        3.56395803e-02, -4.10020985e-02, -1.31450474e-01,  1.06171392e-01,\n",
       "       -7.08466396e-03, -1.56291332e-02,  1.32920966e-03,  2.77859531e-02,\n",
       "        1.44972771e-01,  1.48766279e-01,  1.02573577e-02,  4.88163680e-02,\n",
       "        1.39070272e-01,  5.05012646e-02, -3.19880471e-02, -6.14840984e-02,\n",
       "       -5.12176991e-01, -1.48223862e-01,  4.49847206e-02,  6.55371100e-02,\n",
       "       -1.00251280e-01, -1.32420287e-01,  1.95517629e-01,  1.06737562e-01,\n",
       "       -1.68236140e-02, -7.80605674e-02, -8.38707536e-02,  3.39357778e-02,\n",
       "       -4.62345108e-02, -1.39445588e-02,  2.12734938e-01,  1.80995822e-01,\n",
       "       -1.91092342e-02,  9.40321535e-02,  4.10124883e-02,  1.23905301e-01,\n",
       "        1.86455175e-01,  1.64936677e-01, -1.14201531e-01,  6.23365492e-02,\n",
       "        1.53899223e-01,  1.58999488e-01, -7.74829239e-02, -6.65909611e-03,\n",
       "        7.69828111e-02,  8.00051168e-02, -7.83357620e-02, -6.34437427e-02,\n",
       "        1.38656363e-01,  7.16703711e-03, -1.01775184e-01,  2.19722018e-02,\n",
       "        2.17676796e-02, -1.53060675e+00,  1.86601892e-01,  2.70866621e-02,\n",
       "       -8.74964073e-02, -1.18680447e-02,  6.72526285e-02,  1.31774992e-01,\n",
       "        9.28530395e-02,  7.28591904e-03,  5.37430122e-03,  7.46702924e-02,\n",
       "        1.13517694e-01,  2.01860666e-01, -1.01739496e-01,  1.13433767e-02,\n",
       "        1.03078216e-01, -1.05684280e-01, -7.48372301e-02,  3.80534935e-03,\n",
       "       -3.62213627e-02,  1.78623289e-01,  2.86509208e-02, -5.26040792e-04,\n",
       "        2.01520070e-01, -1.67415626e-02, -5.45788258e-02,  3.18040177e-02,\n",
       "        6.99362904e-02,  4.21780273e-02, -7.29165897e-02, -3.04907002e-03,\n",
       "        1.19230315e-01,  1.24400824e-01,  5.26070036e-03, -5.83057851e-02,\n",
       "        3.66889313e-02, -1.70204327e-01,  1.10855147e-01,  2.56314456e-01,\n",
       "        2.83829737e-02, -1.32760763e-01,  1.10110678e-01, -5.58640584e-02,\n",
       "       -1.15730152e-01,  1.19471237e-01, -1.11707494e-01, -2.72214450e-02,\n",
       "        6.91439584e-02, -7.40119219e-02,  1.80592164e-02,  5.83279021e-02,\n",
       "        1.78675633e-02,  3.76277119e-02,  6.76780343e-02, -1.03768542e-01,\n",
       "        3.85981090e-02,  1.03615806e-01, -3.64412926e-02,  1.03812136e-01,\n",
       "       -9.14832279e-02, -3.15867588e-02,  5.91649860e-02, -1.03599794e-01,\n",
       "        2.65130289e-02,  3.56045142e-02,  1.72168121e-01,  4.80839647e-02,\n",
       "       -1.52146071e-01, -8.71260390e-02, -9.91489738e-02, -9.34451148e-02,\n",
       "       -5.30483201e-04,  1.24891177e-01, -5.84151000e-02, -5.13757281e-02,\n",
       "       -3.91084366e-02, -1.69198394e-01,  1.52963191e-01,  6.18147030e-02,\n",
       "       -2.70389095e-02, -2.92384848e-02,  3.91923729e-03,  3.24105397e-02,\n",
       "       -1.79380327e-02, -7.70555735e-02,  8.98172241e-03, -9.33022425e-03,\n",
       "        3.39216962e-02, -5.37350476e-02, -2.49975957e-02,  2.56089270e-01,\n",
       "        1.17413625e-01, -2.46254772e-01, -9.43997949e-02,  1.23796135e-01,\n",
       "        9.40941423e-02,  9.97972041e-02, -8.52485895e-02, -2.12371349e-01,\n",
       "        3.02630663e-02,  1.29691511e-01,  1.02845088e-01,  1.39732361e-01,\n",
       "        2.15220556e-01,  3.76016423e-02, -1.29511520e-01, -7.61584640e-02,\n",
       "        1.73470408e-01,  1.26646459e-02,  1.13242798e-01,  7.40731061e-02,\n",
       "        1.85242876e-01, -2.27846615e-02, -7.08581582e-02,  7.27757737e-02,\n",
       "       -9.77549702e-04, -1.50567934e-01,  6.00030906e-02, -2.26234607e-02,\n",
       "       -8.51241052e-02, -9.71880332e-02, -2.63709277e-01,  2.42797546e-02,\n",
       "        7.01172203e-02,  6.47229478e-02, -1.60808593e-01,  2.93192089e-01,\n",
       "       -7.10229576e-03, -9.37222838e-02,  6.24862053e-02, -8.77938047e-02,\n",
       "       -2.70259194e-02,  1.20229192e-01,  1.99577078e-01, -1.15199294e-02,\n",
       "        1.13696329e-01, -2.78254692e-03, -2.18298495e-01, -1.95590600e-01,\n",
       "       -5.55945560e-02,  3.83005068e-02,  1.67332605e-01,  6.89623356e-02,\n",
       "        2.88320221e-02, -4.43974659e-02,  1.28958941e-01,  1.45049170e-01,\n",
       "        5.82866706e-02,  1.38981491e-01,  8.22732225e-02,  1.12700552e-01,\n",
       "       -9.60856527e-02,  1.73068479e-01,  1.39462560e-01, -5.92780160e-03,\n",
       "       -1.28955066e-01,  1.66724801e-01, -1.55367285e-01, -3.31005991e-01,\n",
       "        7.95071796e-02, -1.35276675e-01,  7.71667063e-02,  1.28810361e-01,\n",
       "        4.63831685e-02,  2.57650375e-01, -3.64616290e-02,  7.77958855e-02,\n",
       "        1.19901240e-01, -1.29868969e-01,  1.41953692e-01, -7.96466544e-02,\n",
       "        1.86883584e-01,  1.37839317e-01,  3.40323523e-02, -5.16478950e-03,\n",
       "       -1.82168007e-01,  2.24716403e-03,  2.08498493e-01,  1.36182919e-01,\n",
       "        6.00486286e-02,  8.00420865e-02,  1.15679346e-01,  2.26585597e-01,\n",
       "       -1.60314128e-01,  1.51213288e-01,  2.16887817e-02, -7.90632814e-02,\n",
       "        3.79033946e-02,  1.56620368e-02,  6.10232837e-02,  3.84574495e-02,\n",
       "        2.96314023e-02, -1.59530595e-01, -2.61432379e-02,  3.15326080e-03,\n",
       "       -5.72126061e-02,  2.94295438e-02, -6.99321851e-02, -1.34238183e-01,\n",
       "        1.01970874e-01,  1.83877200e-01,  2.55066007e-02,  1.42779902e-01,\n",
       "       -1.80837065e-01, -1.60944294e-02,  7.51547813e-02, -2.76814625e-02,\n",
       "        1.93207376e-02, -4.00281185e-03, -1.69057444e-01,  1.07436799e-01,\n",
       "       -1.14691369e-01,  1.63252115e-01,  1.04153223e-01, -1.61234885e-02,\n",
       "       -5.83166182e-02,  1.84801549e-01,  1.41561851e-01, -2.08247732e-02,\n",
       "       -3.50343361e-02, -1.76764838e-03, -3.61622497e-02,  3.43285836e-02,\n",
       "       -2.48753414e-01,  9.98089276e-03,  6.36391491e-02,  4.51386459e-02,\n",
       "        1.47939518e-01,  1.38583720e-01, -2.16803215e-02, -9.38041732e-02,\n",
       "        6.49127066e-02, -1.05933091e-02,  1.11693829e-01,  1.69903934e-01,\n",
       "        2.55546700e-02,  1.21378072e-01, -6.47189915e-02, -7.16928244e-02,\n",
       "       -7.09402189e-03, -4.80844155e-02, -2.19367728e-01,  9.44329649e-02,\n",
       "        8.40294734e-02,  4.61890362e-03, -1.04874253e-01, -3.12845558e-02,\n",
       "       -3.47925983e-02,  9.52233747e-03,  5.82764670e-02,  9.12369341e-02,\n",
       "       -9.09609348e-02, -5.46307191e-02,  7.45192692e-02,  3.42590176e-02,\n",
       "        1.48249805e-01, -1.34188294e-01,  1.27680689e-01, -2.38624308e-02,\n",
       "       -4.62582707e-02,  9.60369930e-02,  1.58817232e-01,  1.61713019e-01,\n",
       "        4.97260317e-02,  9.36045349e-02, -6.18089698e-02, -2.86438409e-02,\n",
       "        5.44022210e-02,  2.62542158e-01, -3.56324017e-02,  1.96467444e-01,\n",
       "        7.20602646e-02, -9.64794308e-02, -8.21798593e-02, -5.06843813e-02,\n",
       "        1.76682502e-01,  4.86204997e-02,  4.17470001e-02,  3.96825559e-02,\n",
       "        1.95513573e-02,  5.13888896e-04,  1.54948294e-01,  9.78922397e-02,\n",
       "       -5.30730784e-02, -1.67349488e-01,  8.80826935e-02,  1.94193721e-02,\n",
       "       -2.21968710e-01, -5.28025106e-02, -4.49149162e-02,  5.15032858e-02,\n",
       "        1.97126508e-01, -6.34859577e-02,  7.80249909e-02,  1.90171991e-02,\n",
       "        4.81830165e-02, -6.77144378e-02, -4.61560898e-02,  1.28824592e-01,\n",
       "        1.61638916e-01,  7.06778616e-02,  1.09601319e-01,  4.21322063e-02,\n",
       "       -1.01148762e-01,  2.61803687e-01,  4.04229313e-02, -6.35607690e-02,\n",
       "       -3.92633751e-02, -2.91216493e-01,  9.57848579e-02,  3.12957242e-02,\n",
       "       -1.05199561e-01,  9.90275368e-02, -2.43026465e-01,  8.89414623e-02,\n",
       "       -4.02348973e-02,  2.06379816e-01,  3.11672799e-02,  5.78347072e-02,\n",
       "       -1.69140026e-01,  6.73679169e-03, -1.21539839e-01, -9.66685712e-02,\n",
       "       -1.39505550e-01,  1.03419274e-02, -1.94251686e-02,  7.26584271e-02,\n",
       "       -9.48588699e-02,  7.74276480e-02, -3.67054604e-02, -5.47637232e-02,\n",
       "        2.22891435e-01, -1.81389637e-02,  4.99358624e-02, -1.26500398e-01,\n",
       "       -1.71412081e-02,  6.30197451e-02, -2.75264345e-02,  6.09148387e-03,\n",
       "       -1.59878954e-01, -1.10150948e-02, -4.46171537e-02,  2.26854645e-02,\n",
       "       -1.07409135e-01, -8.46719444e-02,  3.99599411e-03,  7.99090266e-02,\n",
       "       -1.13377422e-01,  6.21566176e-02,  7.41002560e-02, -3.51052806e-02,\n",
       "        9.13315788e-02, -5.00378087e-02, -1.55893788e-02, -1.00678548e-01,\n",
       "        1.70864075e-01,  9.93232951e-02,  7.91476145e-02,  7.45924190e-02,\n",
       "       -8.74327347e-02,  6.15670532e-03, -8.68922919e-02,  5.85626438e-02,\n",
       "       -1.39323369e-01, -4.13600355e-02, -8.24957043e-02, -3.77420262e-02,\n",
       "       -2.28495542e-02,  9.45271775e-02,  1.86632425e-02, -4.78400663e-03,\n",
       "        4.25882749e-02,  9.29430872e-02, -1.01119608e-01,  1.24619834e-01,\n",
       "       -2.78131664e-02, -8.78469944e-02, -2.37223487e-02,  1.07059814e-01,\n",
       "       -3.85168791e-01,  1.49631411e-01, -1.41422087e-02,  2.03875713e-02,\n",
       "        2.31798500e-01,  4.34556752e-01, -1.28240541e-01, -9.25645679e-02,\n",
       "       -5.10717705e-02, -2.02508755e-02, -3.66543494e-02, -7.76857138e-02,\n",
       "        1.42560095e-01,  1.83855131e-01, -2.83836842e-01,  6.08733445e-02,\n",
       "        5.77601679e-02, -7.01707974e-03, -8.64606537e-03,  6.15338460e-02,\n",
       "       -9.52325687e-02,  9.27427933e-02,  1.51184425e-01, -3.50598320e-02,\n",
       "        8.44211131e-03,  3.07543993e-01, -5.74374855e-01,  1.08993929e-02,\n",
       "       -1.18819676e-01,  1.71941310e-01,  2.37835273e-02,  4.25862372e-02,\n",
       "        2.27644369e-02, -1.35157302e-01, -1.30298845e-02, -2.00194474e-02,\n",
       "       -9.09441188e-02,  8.24412405e-02,  1.05100505e-01, -1.11322477e-02,\n",
       "        7.83461407e-02,  1.02570310e-01,  6.64273882e-03,  1.14050433e-01,\n",
       "        4.50837761e-02,  3.40376049e-03, -7.30262399e-02,  1.16496250e-01,\n",
       "        1.24176547e-01, -1.42160147e-01,  8.39968175e-02,  5.75552648e-03,\n",
       "       -6.93547204e-02,  6.30626231e-02, -6.77238852e-02, -8.46984759e-02,\n",
       "       -1.00971967e-01, -4.84560477e-03,  2.63942243e-03, -7.43023083e-02,\n",
       "        2.27128211e-02,  9.43882391e-03,  1.19384870e-01,  1.99180335e-01,\n",
       "        4.82973158e-02,  1.29217133e-01,  5.76438271e-02, -1.17249694e-02,\n",
       "       -5.95074594e-02, -1.26342088e-01, -1.02177098e-01, -3.70973125e-02,\n",
       "       -2.02061087e-01,  1.73656017e-01, -8.21707547e-02,  4.25370745e-02,\n",
       "        1.55024871e-01, -7.49204084e-02, -1.80113167e-02, -6.08728975e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Ceci est un test avec une phrase un peu plus longue. On verra ce que ca donne...'\n",
    "get_embeddings(sentence,tokenizer,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf586b92",
   "metadata": {},
   "source": [
    "## Calcul des embeddings des textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd02103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717298aee8b34968b9179a0362c1cd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/904 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_label['embeddings']=df_label['text'].progress_apply(lambda text: get_embeddings(text,tokenizer,model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d7442",
   "metadata": {},
   "source": [
    "## Prédiction infox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d87b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf87a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_df_ml(label,df_label):\n",
    "    df_0 = df_label[df_label[label] == 0]\n",
    "    df_1 = df_label[df_label[label] == 1]\n",
    "    min_sample = min(len(df_0),len(df_1))\n",
    "    df_0=df_0.sample(min_sample,random_state=_rs)\n",
    "    df_1=df_1.sample(min_sample,random_state=_rs)\n",
    "    df_ml = pd.concat([df_0,df_1])\n",
    "    df_ml = df_ml.sample(frac=1,random_state=_rs)\n",
    "    return df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11178211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = get_balanced_df_ml('infox',df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2827113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6dca47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([r['embeddings'] for i,r in df_ml.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd587e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bedc7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ml['infox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a28c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=_rs, solver='lbfgs', multi_class='ovr', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26ec979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(logreg, X, y, cv=4,scoring=('roc_auc','f1','accuracy','precision','recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4e59892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time          0.044024\n",
       "score_time        0.008357\n",
       "test_roc_auc      0.838486\n",
       "test_f1           0.748893\n",
       "test_accuracy     0.760106\n",
       "test_precision    0.784991\n",
       "test_recall       0.718628\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c9861",
   "metadata": {},
   "source": [
    "## Prédiction liste de labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e17d8f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['infox', 'entites_nommees', 'ouverture_esprit', 'faits', 'opinions',\n",
    "       'propos_raportes', 'sources_citees', 'fausse_nouvelle', 'insinuations',\n",
    "       'exageration', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5a72be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_ml(label,df_label):\n",
    "    return df_label[df_label[label].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef6bbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_df_ml(label,df_label):\n",
    "    df_0 = df_label[df_label[label] == 0]\n",
    "    df_1 = df_label[df_label[label] == 1]\n",
    "    min_sample = min(len(df_0),len(df_1))\n",
    "    df_0=df_0.sample(min_sample,random_state=_rs)\n",
    "    df_1=df_1.sample(min_sample,random_state=_rs)\n",
    "    df_ml = pd.concat([df_0,df_1])\n",
    "    df_ml = df_ml.sample(frac=1,random_state=_rs)\n",
    "    return df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50f4da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(label,df_ml):\n",
    "    logreg = LogisticRegression(C=100,random_state=_rs, solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "    matrix = np.array([r['embeddings'] for i,r in df_ml.iterrows()])\n",
    "    X = pd.DataFrame(matrix)\n",
    "    y = df_ml[label]\n",
    "    classifier = logreg\n",
    "    scores = cross_validate(classifier, X, y, cv=4,scoring=('roc_auc','f1','accuracy','precision','recall'))\n",
    "    df_scores=pd.DataFrame(scores)\n",
    "    score_dic = df_scores.mean().to_dict()\n",
    "    score_dic['label']=label\n",
    "    score_dic['n_samples']=len(df_ml)\n",
    "    return score_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8192fe26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing infox\n",
      "Processing entites_nommees\n",
      "Processing ouverture_esprit\n",
      "Processing faits\n",
      "Processing opinions\n",
      "Processing propos_raportes\n",
      "Processing sources_citees\n",
      "Processing fausse_nouvelle\n",
      "Processing insinuations\n",
      "Processing exageration\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "for label in labels:\n",
    "    print(f'Processing {label}')\n",
    "    df_ml = get_balanced_df_ml(label,df_label)\n",
    "    score_list.append(get_scores(label,df_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f88c0f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>label</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.204311</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.806511</td>\n",
       "      <td>0.716340</td>\n",
       "      <td>0.725231</td>\n",
       "      <td>0.741514</td>\n",
       "      <td>0.694349</td>\n",
       "      <td>infox</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195557</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.667461</td>\n",
       "      <td>0.637787</td>\n",
       "      <td>0.635260</td>\n",
       "      <td>0.635635</td>\n",
       "      <td>0.641576</td>\n",
       "      <td>entites_nommees</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057497</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.490015</td>\n",
       "      <td>0.483891</td>\n",
       "      <td>0.470769</td>\n",
       "      <td>0.472588</td>\n",
       "      <td>0.508013</td>\n",
       "      <td>ouverture_esprit</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.156301</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.630469</td>\n",
       "      <td>0.622830</td>\n",
       "      <td>0.618926</td>\n",
       "      <td>0.615948</td>\n",
       "      <td>0.630561</td>\n",
       "      <td>faits</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230577</td>\n",
       "      <td>0.007785</td>\n",
       "      <td>0.648533</td>\n",
       "      <td>0.608811</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.619753</td>\n",
       "      <td>0.598901</td>\n",
       "      <td>opinions</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.126148</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.616306</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>propos_raportes</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.248850</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.579437</td>\n",
       "      <td>0.551167</td>\n",
       "      <td>0.562112</td>\n",
       "      <td>0.566377</td>\n",
       "      <td>0.537191</td>\n",
       "      <td>sources_citees</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.090349</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.608737</td>\n",
       "      <td>0.589782</td>\n",
       "      <td>0.577869</td>\n",
       "      <td>0.570344</td>\n",
       "      <td>0.614785</td>\n",
       "      <td>fausse_nouvelle</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.178159</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.708899</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.648496</td>\n",
       "      <td>0.653670</td>\n",
       "      <td>0.639360</td>\n",
       "      <td>insinuations</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.119112</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.670602</td>\n",
       "      <td>0.606895</td>\n",
       "      <td>0.611383</td>\n",
       "      <td>0.615636</td>\n",
       "      <td>0.600026</td>\n",
       "      <td>exageration</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_roc_auc   test_f1  test_accuracy  \\\n",
       "0  0.204311    0.008248      0.806511  0.716340       0.725231   \n",
       "1  0.195557    0.008036      0.667461  0.637787       0.635260   \n",
       "2  0.057497    0.007549      0.490015  0.483891       0.470769   \n",
       "3  0.156301    0.007646      0.630469  0.622830       0.618926   \n",
       "4  0.230577    0.007785      0.648533  0.608811       0.615385   \n",
       "5  0.126148    0.007612      0.616306  0.583541       0.591837   \n",
       "6  0.248850    0.007780      0.579437  0.551167       0.562112   \n",
       "7  0.090349    0.007559      0.608737  0.589782       0.577869   \n",
       "8  0.178159    0.007935      0.708899  0.645714       0.648496   \n",
       "9  0.119112    0.007674      0.670602  0.606895       0.611383   \n",
       "\n",
       "   test_precision  test_recall             label  n_samples  \n",
       "0        0.741514     0.694349             infox        746  \n",
       "1        0.635635     0.641576   entites_nommees        614  \n",
       "2        0.472588     0.508013  ouverture_esprit        102  \n",
       "3        0.615948     0.630561             faits        454  \n",
       "4        0.619753     0.598901          opinions        728  \n",
       "5        0.598400     0.571429   propos_raportes        392  \n",
       "6        0.566377     0.537191    sources_citees        644  \n",
       "7        0.570344     0.614785   fausse_nouvelle        244  \n",
       "8        0.653670     0.639360      insinuations        532  \n",
       "9        0.615636     0.600026       exageration        350  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76996d3a",
   "metadata": {},
   "source": [
    "# Sauvegarde des résultats\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd7c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f8729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7949bc",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd360655",
   "metadata": {},
   "source": [
    "# Bricolages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9862890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.model.camembert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3262dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(patat.model.camembert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e0315",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = patat.model.camembert.Camembert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c0221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c182439",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2 = model.get_embeddings('Voici est un autre texte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d790a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([df_label['embeddings'][0],df_label['embeddings'][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1586e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
