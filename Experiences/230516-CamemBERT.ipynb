{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca06de0a",
   "metadata": {},
   "source": [
    "# Plateforme Agnostique de Traitement et d'Analyse des Textes\n",
    "### Carnet d'expérimentation\n",
    "---\n",
    "\n",
    "## Sujet : CamemBERT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e020924a",
   "metadata": {},
   "source": [
    "# Environnement\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53aa23f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Geek/Work/Patat\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde87f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3456a8f8",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "226312f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Vendredi soir est la nuit de ma fête de la sem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Chiffres. Un jour de congé demain et la prévis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Alecyberspace quelque chose doit être fait !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Je pense que nous devrions faire du spaghetti Sme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Sera un forum publicitaire de masse aujourd'hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>À la maison du travail ... woot! Bat la nuit d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>Comment allez-vous faire cela?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "      <td>La musique sonne f-i-t cette veille ensoleillé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1</td>\n",
       "      <td>: 20somethin 'single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>J'espère! Mon sis arrive à choisir car elle a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         0  Vendredi soir est la nuit de ma fête de la sem...\n",
       "1         0  Chiffres. Un jour de congé demain et la prévis...\n",
       "2         0      Alecyberspace quelque chose doit être fait !!\n",
       "3         1  Je pense que nous devrions faire du spaghetti Sme\n",
       "4         0  Sera un forum publicitaire de masse aujourd'hu...\n",
       "...     ...                                                ...\n",
       "4995      0  À la maison du travail ... woot! Bat la nuit d...\n",
       "4996      1                     Comment allez-vous faire cela?\n",
       "4997      1  La musique sonne f-i-t cette veille ensoleillé...\n",
       "4998      1                               : 20somethin 'single\n",
       "4999      0  J'espère! Mon sis arrive à choisir car elle a ...\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/tmp/french_tweets.csv'\n",
    "df_tweets = pd.read_csv(filename).sample(5000).reset_index(drop=True)\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f22b0fd",
   "metadata": {},
   "source": [
    "## GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b63c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n",
      "torch_device = mps \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch_device='cpu'\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch_device='mps'\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "print(f'torch_device = {torch_device} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4ec5d",
   "metadata": {},
   "source": [
    "# Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1111f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange, tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c191e34b",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006ee53",
   "metadata": {},
   "source": [
    "## CamemBERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ea2c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ad899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58cbecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_tweets.sample(1)['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e6f956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1bbe01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221c3e5ca55f42acaaa3c701943a9e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tweets['bert_tokens']=df_tweets['text'].progress_apply(bert_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23666b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [▁Vendredi, ▁soir, ▁est, ▁la, ▁nuit, ▁de, ▁ma,...\n",
       "1       [▁Chiffre, s, ., ▁Un, ▁jour, ▁de, ▁congé, ▁dem...\n",
       "2       [▁A, le, cy, ber, space, ▁quelque, ▁chose, ▁do...\n",
       "3       [▁Je, ▁pense, ▁que, ▁nous, ▁devrions, ▁faire, ...\n",
       "4       [▁Ser, a, ▁un, ▁forum, ▁publicitaire, ▁de, ▁ma...\n",
       "                              ...                        \n",
       "4995    [▁À, ▁la, ▁maison, ▁du, ▁travail, ▁..., ▁wo, o...\n",
       "4996        [▁Comment, ▁allez, -, vous, ▁faire, ▁cela, ?]\n",
       "4997    [▁La, ▁musique, ▁sonne, ▁f, -, i, -, t, ▁cette...\n",
       "4998          [▁:, ▁20, s, ome, th, in, ▁, ', s, ing, le]\n",
       "4999    [▁J, ', espère, !, ▁Mon, ▁si, s, ▁arrive, ▁à, ...\n",
       "Name: bert_tokens, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['bert_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d243026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['btokens_count'] = df_tweets['bert_tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69a9b403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "976afdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x3bad92c40>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(df_tweets,x='btokens_count',bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92a0f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_tweets.sample(1)['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c44080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═════════════╕\n",
      "│ Tokens    │   Token IDs │\n",
      "╞═══════════╪═════════════╡\n",
      "│ ▁Oh       │        4684 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁internet │         890 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁où       │         147 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁es       │        1252 │\n",
      "├───────────┼─────────────┤\n",
      "│ -         │          26 │\n",
      "├───────────┼─────────────┤\n",
      "│ tu        │         744 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁toute    │         194 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁ma       │         155 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁vie      │         157 │\n",
      "╘═══════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "table = np.array([bert_tokenizer.tokenize(text), \n",
    "                bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(text))]).T\n",
    "print(tabulate(table,\n",
    "         headers = ['Tokens', 'Token IDs'],\n",
    "         tablefmt = 'fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d3ee8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_tweets['text']\n",
    "labels = df_tweets['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "828e3229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═════════════╕\n",
      "│ Tokens    │   Token IDs │\n",
      "╞═══════════╪═════════════╡\n",
      "│ ▁Om       │       14236 │\n",
      "├───────────┼─────────────┤\n",
      "│ g         │         383 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁les      │          19 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁collines │       15680 │\n",
      "├───────────┼─────────────┤\n",
      "│ !         │         152 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁Alors    │         574 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁j        │          76 │\n",
      "├───────────┼─────────────┤\n",
      "│ '         │          11 │\n",
      "├───────────┼─────────────┤\n",
      "│ aime      │         660 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁l        │          17 │\n",
      "├───────────┼─────────────┤\n",
      "│ '         │          11 │\n",
      "├───────────┼─────────────┤\n",
      "│ argent    │        1042 │\n",
      "├───────────┼─────────────┤\n",
      "│ 2,        │        3502 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁a        │          33 │\n",
      "├───────────┼─────────────┤\n",
      "│ w         │         640 │\n",
      "├───────────┼─────────────┤\n",
      "│ w         │         640 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁je       │          50 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁pense    │         500 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁que      │          27 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁bec      │       12750 │\n",
      "├───────────┼─────────────┤\n",
      "│ ky        │        6177 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁bu       │        4175 │\n",
      "├───────────┼─────────────┤\n",
      "│ ck        │        1806 │\n",
      "├───────────┼─────────────┤\n",
      "│ wi        │        4672 │\n",
      "├───────────┼─────────────┤\n",
      "│ ld        │        8163 │\n",
      "├───────────┼─────────────┤\n",
      "│ ▁va       │         198 │\n",
      "╘═══════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "tokenizer = bert_tokenizer\n",
    "def print_rand_sentence():\n",
    "    '''Displays the tokens and respective IDs of a random text sample'''\n",
    "    index = random.randint(0, len(texts)-1)\n",
    "    table = np.array([tokenizer.tokenize(texts[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(texts[index]))]).T\n",
    "    print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fce76",
   "metadata": {},
   "source": [
    "# Sentence Encoding / Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d41ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/gpu39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/var/folders/fr/mhrqmk5n1xs49b7jl3tgs2r00000gn/T/ipykernel_28467/687045473.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "    '''\n",
    "    Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "    '''\n",
    "    return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 32,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "\n",
    "for sample in texts:\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be03c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════╤═════════════╤══════════════════╕\n",
      "│ Tokens      │   Token IDs │   Attention Mask │\n",
      "╞═════════════╪═════════════╪══════════════════╡\n",
      "│ <s>         │           5 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁J          │         121 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ '           │          11 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ai          │          73 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁plongé     │       14950 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁plusieurs  │         247 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁fois       │         151 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁pour       │          24 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁la         │          13 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁balle      │        5417 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ .           │           9 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁A          │         114 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁réussi     │        1522 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁à          │          15 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁économiser │       16524 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁50%        │        7651 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁le         │          16 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁reste      │         353 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁sort       │        1401 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁de         │           8 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ▁limites    │        3311 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ </s>        │           6 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ <pad>       │           1 │                0 │\n",
      "╘═════════════╧═════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence_encoding():\n",
    "    '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
    "    index = random.randint(0, len(texts) - 1)\n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
    "    token_ids = [i.numpy() for i in token_id[index]]\n",
    "    attention = [i.numpy() for i in attention_masks[index]]\n",
    "\n",
    "    table = np.array([tokens, token_ids, attention]).T\n",
    "    print(tabulate(table, \n",
    "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024eaca",
   "metadata": {},
   "source": [
    "# Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8c2077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "batch_size = 16\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce68c47",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01ebcbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_tp(preds, labels):\n",
    "    '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
    "    return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fp(preds, labels):\n",
    "    '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
    "    return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_tn(preds, labels):\n",
    "    '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
    "    return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fn(preds, labels):\n",
    "    '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
    "    return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_metrics(preds, labels):\n",
    "    '''\n",
    "    Returns the following metrics:\n",
    "    - accuracy    = (TP + TN) / N\n",
    "    - precision   = TP / (TP + FP)\n",
    "    - recall      = TP / (TP + FN)\n",
    "    - specificity = TN / (TN + FP)\n",
    "    '''\n",
    "    preds = np.argmax(preds, axis = 1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    tp = b_tp(preds, labels)\n",
    "    tn = b_tn(preds, labels)\n",
    "    fp = b_fp(preds, labels)\n",
    "    fn = b_fn(preds, labels)\n",
    "    b_accuracy = (tp + tn) / len(labels)\n",
    "    b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
    "    b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
    "    b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
    "    return b_accuracy, b_precision, b_recall, b_specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db13c96",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9d8a2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "# Load the BertForSequenceClassification model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'camembert-base',\n",
    "    num_labels = 1,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr = 5e-5,\n",
    "                              eps = 1e-08\n",
    "                              )\n",
    "\n",
    "# Run on GPU\n",
    "#model.cuda()\n",
    "#model.to('cpu')\n",
    "model.to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd7a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9018ef8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|███████████████████████████████████████████                                           | 1/2 [00:07<00:07,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.0013\n",
      "\t - Validation Accuracy: 1.0000\n",
      "\t - Validation Precision: NaN\n",
      "\t - Validation Recall: NaN\n",
      "\t - Validation Specificity: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.0004\n",
      "\t - Validation Accuracy: 1.0000\n",
      "\t - Validation Precision: NaN\n",
      "\t - Validation Recall: NaN\n",
      "\t - Validation Specificity: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#device=torch.device('cpu')\n",
    "device=torch.device(torch_device)\n",
    "#device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "epochs = 2\n",
    "for _ in trange(epochs, desc = 'Epoch'):\n",
    "    \n",
    "    # ========== Training ==========\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        batch = tuple(t.to(torch.float32).to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids.to(torch.int), \n",
    "                             token_type_ids = None, \n",
    "                             attention_mask = b_input_mask, \n",
    "                             labels = b_labels)\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    # ========== Validation ==========\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_specificity = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(torch.float32).to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          # Forward pass\n",
    "          eval_output = model(b_input_ids.to(torch.int), \n",
    "                              token_type_ids = None, \n",
    "                              attention_mask = b_input_mask)\n",
    "        logits = eval_output.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate validation metrics\n",
    "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update precision only when (tp + fp) !=0; ignore nan\n",
    "        if b_precision != 'nan': val_precision.append(b_precision)\n",
    "        # Update recall only when (tp + fn) !=0; ignore nan\n",
    "        if b_recall != 'nan': val_recall.append(b_recall)\n",
    "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
    "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86782399",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ae894d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e5fc1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = 'Please update your account data at https://dsfsdsq.ru/sd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "778c9f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence:  Please update your account data at https://dsfsdsq.ru/sd\n",
      "Predicted Class:  Non Infox\n"
     ]
    }
   ],
   "source": [
    "# We need Token IDs and Attention Mask for inference on the new sentence\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim = 0)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "# Forward pass, calculate logit predictions\n",
    "with torch.no_grad():\n",
    "  output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "\n",
    "prediction = 'Infox' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'Non Infox'\n",
    "\n",
    "print('Input Sentence: ', new_sentence)\n",
    "print('Predicted Class: ', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e37ad",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68265485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ed94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip -o smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a896b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b6f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/prod/230512-OIDS-Label.csv'\n",
    "df_label = patat.util.pd.df_from_csvjson(['tags','paragraphs'],filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_label['title'].values\n",
    "labels = df_label['infox'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf3abf",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82344fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!conda install transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b75c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install tabulate -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
